<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Danny Navarro's blog]]></title>
  <link href="http://dannynavarro.net/atom.xml" rel="self"/>
  <link href="http://dannynavarro.net/"/>
  <updated>2014-04-08T14:20:41+02:00</updated>
  <id>http://dannynavarro.net/</id>
  <author>
    <name><![CDATA[Danny Navarro]]></name>
    <email><![CDATA[j@dannynavarro.net]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Haskell role in FP paradigm shift]]></title>
    <link href="http://dannynavarro.net/2014/04/08/haskell-role-in-fp-paradigm-shift/"/>
    <updated>2014-04-08T13:44:28+02:00</updated>
    <id>http://dannynavarro.net/2014/04/08/haskell-role-in-fp-paradigm-shift</id>
    <content type="html"><![CDATA[<p>I was listening to <a href="https://en.wikipedia.org/wiki/Bruce_Tate">Bruce Tate</a> in <a href="http://mostlyerlang.com/">Mostly Erlang</a> podcast, when, around
the 57th minute of <a href="http://mostlyerlang.com/2014/03/04/031-bruce-tate/">the episode</a>, the topic of the conversation
became the feasibility of <a href="https://en.wikipedia.org/wiki/Functional_programming">FP</a> becoming mainstream. He explains that <a href="https://en.wikipedia.org/wiki/Functional_programming">FP</a>
has not emerged yet, but it&rsquo;s reluctantly about to do so, being the end of
Moore&rsquo;s law the main driver as concurrent/parallel programming becomes
more critical.</p>

<p>I agree with him about this trend, although I also think it&rsquo;s easy to
overestimate the time it will take. I think it&rsquo;s going to be very slow.</p>

<p>Another interesting idea, he mentions is that within the <a href="https://en.wikipedia.org/wiki/Functional_programming">FP</a> field, a clear
<em>winner</em> may arise, as it happened with the C/C++, and all its descendants. The
four candidates he postulates are:</p>

<ul>
<li><a href="http://www.erlang.org/">Erlang</a>/<a href="http://elixir-lang.org/">Elixir</a></li>
<li><a href="http://clojure.org/">Clojure</a></li>
<li><a href="http://www.scala-lang.org/">Scala</a></li>
<li><a href="https://en.wikipedia.org/wiki/Javascript">JavaScript</a></li>
</ul>


<p>He dismisses <a href="http://www.haskell.org/">Haskell</a> for not being approachable enough, similarly to when
<a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)">Lisp</a> came out.</p>

<p>I also think there&rsquo;ll be a <em>winner</em>, understanding for <em>winner</em>, the
language most programmers and companies will use (i.e. Java would be a
<em>winner</em> now). But I don&rsquo;t see being a  <em>winner</em> language, in this sense,
so relevant. To me, what&rsquo;s really important is to see how prominent is
going to be the software written in that language, and how much of current
business will be run in code written in such language. A language could be
considered not mainstream by programmers and companies, but there may be
several critical widespread software that wouldn&rsquo;t be possible without it.
For example, I see this trend going on with <a href="http://www.erlang.org/">Erlang</a> being used in
critical <a href="https://en.wikipedia.org/wiki/Instant_messaging">IM</a> services, distributed databases, message queuing systems,
etc. Current shops with expertise in <a href="http://www.erlang.org/">Erlang</a>, even if not mainstream,
have a clear competitive advantage when writing scalable systems.</p>

<p>In this sense, I think <a href="http://www.haskell.org/">Haskell</a> may never be a <em>winner</em>, but the question
is still open about how crucial will it be in the future. What will be the
business perspectives for the few companies proficient in <a href="http://www.haskell.org/">Haskell</a>? Who
cares if there are few proficient <a href="http://www.haskell.org/">Haskell</a> programmers as long as there
is a pool of <a href="http://www.haskell.org/">Haskell</a> programmers to hire (which currently it seems there
is) and taking into account the strong hint that if someone is proficient
<a href="http://www.haskell.org/">Haskell</a> she has already very high chances of being a very productive
programmer?</p>

<p>I guess this <a href="http://paulgraham.com/avg.html">same argument</a> was the same used with <a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)">Lisp</a>, but now
there are some differences. <a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)">Lisp</a> idioms are, inherently, very
heterogeneous, whereas <a href="http://www.haskell.org/">Haskell</a>, in spite of not having the equivalent of
being <a href="http://blog.startifact.com/posts/older/what-is-pythonic.html">Pythonic</a>, is much more understandable among programmers working in
different projects. Secondly, there are certain
parallelization/concurrency problems that are very hard to get them right
with traditional languages, for example, <a href="https://en.wikipedia.org/wiki/Software_transactional_memory">STM</a>. I&rsquo;m not an expert in
<a href="https://en.wikipedia.org/wiki/Lisp_(programming_language)">Lisp</a> but I guess it lacked the killer feature that make using it a need,
more than just a nice advantage.</p>

<p>In conclusion, my opinion is that <a href="http://www.haskell.org/">Haskell</a> has a very good chance of
becoming very relevant even if it doesn&rsquo;t become the <a href="https://en.wikipedia.org/wiki/Functional_programming">FP</a> language
<em>winner</em>. I see its <a href="https://en.wikipedia.org/wiki/Purely_functional">purity</a> and side-effect management as enablers of
killer features in the area of concurrent/parallel programming. Somehow,
the vibrancy of the <a href="http://www.haskell.org/">Haskell</a> community these days, reminds me of the
[Python] community before Google made it popular. Will all
this be enough to make <a href="http://www.haskell.org/">Haskell</a> relevant? I guess time will tell.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Podcast tribute]]></title>
    <link href="http://dannynavarro.net/2014/03/26/podcast-tribute/"/>
    <updated>2014-03-26T20:53:58+01:00</updated>
    <id>http://dannynavarro.net/2014/03/26/podcast-tribute</id>
    <content type="html"><![CDATA[<p>These days, with the pervasiveness of the Internet, an impressive wave of
new spoken audio content is making steadily its way into the mainstream.
I&rsquo;ve always been a big fan of spoken radio, but now I find myself
listening only to independent <a href="https://en.wikipedia.org/wiki/Podcast">podcasts</a>, mostly hosted by
amateurs, who are able to provide fresh and genuine content in a medium
where innovation has been stagnant for many years.</p>

<p>The least I can do for all the countless hours of entertainment they are
giving me is to publicly express my admiration for them.</p>

<h4><a href="http://www.dancarlin.com/disp.php/hh">Hardcore History</a></h4>

<p>When a new episode of this podcast comes out I try to wrap up everything
I&rsquo;m doing and take a hiking route with my dog long enough to listen to the
new episode uninterrupted. I think what makes <a href="https://en.wikipedia.org/wiki/Dan_Carlin">Dan Carlin</a> outstanding as
a narrator is his great ability to immerse the listener in the situation
of the era and to describe how it felt to be in the shoes of the people
living through it. All in all, after listening to several episodes, I came
to realize we are not so different from our ancestors, and in most cases,
no matter how horrible the consequences of some actions were, we&rsquo;d
probably have done the same.</p>

<h4><a href="http://www.histocast.com">HistoCast (Spanish)</a></h4>

<p>This history podcast is carried in a <a href="https://en.wikipedia.org/wiki/Tertulia"><em>tertulia</em></a> format by a panel of
history aficionados. The general tone is informal but at the same time
it&rsquo;s quite rigorous regarding the information they provide and throughout
in their analysis. The anecdotes they manage to find are priceless.</p>

<h4><a href="http://www.colectivoburbuja.org/">Colectivo Burbuja (Spanish)</a></h4>

<p>When living in a country like <a href="http://www.heritage.org/index/country/spain">Spain</a>, with a government filled with
corrupted crooks who control practically all traditional media outlets,
independent podcasts like this one are really appreciated. It mostly
consists of debates with speakers of diverse ideologies analyzing current
news, mainly economic. It really helps understand what is really going on
in this country, full of strange contradictions.</p>

<h4><a href="https://www.grc.com/securitynow.htm">Security Now</a></h4>

<p><a href="https://en.wikipedia.org/wiki/Steve_Gibson_(computer_programmer)">Steve Gibson</a> could be accused of being an expert in <a href="https://en.wikipedia.org/wiki/Public_relations">PR</a> more than an
expert in information security but, in spite of this, I find hard to deny
his didactic ability to introduce the listener to different security
concepts and to summarize the most important security events of the week.</p>

<h4><a href="http://sixgun.org/linuxoutlaws">Linux Outlaws</a></h4>

<p>By the title one would expect a highly technical podcast, but more than
a podcast about the Linux world, this is about using Linux as a excuse for
numerous ranting, cynical comments and nerdy jokes, which I find really
funny.</p>

<h4><a href="http://12byzantinerulers.com/">12 Byzantine Rulers</a> and <a href="http://normancenturies.com/">Norman Centuries</a></h4>

<p>Even if they are considered podcasts, they feel more like history
audiobooks. <a href="https://en.wikipedia.org/wiki/Lars_brownworth">Lars Brownworth</a> fabulously narrates relatively unknown
amazing epochs which were highly influential but didn&rsquo;t get the historical
popularity they deserved.</p>

<h4><a href="http://podcasts.joerogan.net/">The Joe Rogan Experience</a></h4>

<p><a href="https://en.wikipedia.org/wiki/Joe_Rogan">Joe Rogan</a> interviews in a funny and informal tone diverse personalities.
I view these discussions as examples of honest civilized conversations
between individuals with very different backgrounds. I also found very
interesting podcasters through this podcast.</p>

<h4><a href="http://www.haskellcast.com/">The HaskellCast</a></h4>

<p>Because these days I&rsquo;m coding full-time in <a href="http://www.haskell.org/">Haskell</a>, in this podcast, I
really appreciate the interviews to prominent figures in the community.
What I like the most about listening to them instead of just reading what
they write, is that somehow, by hearing them explain what they do, it&rsquo;s
easier to grasp the train of thought that led them to do what they did.</p>

<h4><a href="http://www.revolutionspodcast.com/">Revolutions</a></h4>

<p>This history podcast is very informationally dense but fun to listen to
nevertheless. <a href="https://en.wikipedia.org/wiki/Mike_Duncan_(podcaster)">Mike Duncan</a> does a great job explaining the high
complexity of events that led to big changes in history. He&rsquo;s also the
author of <a href="http://thehistoryofrome.typepad.com/">History of Rome</a> which I still haven&rsquo;t gone through but hope to
start doing it that at some point.</p>

<h4><a href="http://pasajesdelahistoria.ueuo.com/">Pasajes de la Historia (Spanish)</a></h4>

<p>This is one of the few podcasts I listen that it&rsquo;s taken from traditional
media. Unfortunately, <a href="https://es.wikipedia.org/wiki/Juan_Antonio_Cebri%C3%A1n">Juan Antonio Cebri√°n</a> passed away prematurely but
left an incredible legacy in the form of tales based on historical
figures.</p>

<h4><a href="http://letstalkbitcoin.com/">Let&rsquo;s talk Bitcoin</a></h4>

<p>This is also a podcast I follow for professional reasons. If I had to
choose a single <a href="https://bitcoin.org/">Bitcoin</a> podcast this would be the one.</p>

<!---
vim: tw=74 spell
-->

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[An opinionated importing style for Haskell]]></title>
    <link href="http://dannynavarro.net/2014/03/17/an-opinionated-importing-style-for-haskell/"/>
    <updated>2014-03-17T21:17:15+01:00</updated>
    <id>http://dannynavarro.net/2014/03/17/an-opinionated-importing-style-for-haskell</id>
    <content type="html"><![CDATA[<p>Large part of <a href="http://haskell.org">Haskell</a> code is just about imports. In many programming
languages there is no ambiguity left about how to import, but <a href="http://haskell.org">Haskell</a>
leaves some room for personal style in this regard. There are some
recommendations out there about importing style, but most is left to
common sense. Your own judgment, once you are comfortable with <a href="http://haskell.org">Haskell</a>,
should be perfectly fine, but newcomers who care about style consistency
might feel a bit lost when writing the import list for their own packages
<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>, specially since there are many slightly different styles in the wild
for <a href="http://haskell.org">Haskell</a> imports. In this post, I&rsquo;ll try to explain the rationale of
the style I follow.</p>

<p>One basic principle I&rsquo;ll be following for all my criteria is that, like I
guess most programmers, code style is about reading code, not writing it.
When writing, you can make the assumption that someone editing the code
has access to editing tools, whereas this assumption doesn&rsquo;t hold so
easily for the readers of your code.</p>

<h2>Explicit imports</h2>

<p>Anyone reading the <a href="http://python.org">Python</a> <a href="http://docs.python.org/3/tutorial/index.html">official tutorial</a>
for the first time has to read through this when reaching the section
about <a href="http://docs.python.org/3/tutorial/modules.html#modules">modules</a>:</p>

<blockquote><p>There is even a variant to import all names that a module defines:</p></blockquote>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
</pre></td><td class='code'><pre><code class='python'><span class='line'><span class="kn">from</span> <span class="nn">fibo</span> <span class="kn">import</span> <span class="o">*</span>
</span><span class='line'><span class="n">fib</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<blockquote><p>This imports all names except those beginning with an underscore (<code>_</code>). In
most cases Python programmers do not use this facility since it introduces an
unknown set of names into the interpreter, possibly hiding some things you
have already defined.</p>

<p>Note that in general <strong>the practice of importing <code>*</code> from a module or package is
frowned upon</strong>, since it often causes poorly readable code. However, it is okay
to use it to save typing in interactive sessions.</p></blockquote>

<p>This means that anything but a small <em>built-in</em> language core, which it
can be easily memorized, has to be explicitly exported to be in scope.
This is great for newcomers reading any Python code, you are always aware,
with no extra tools, where everything is coming from.</p>

<p>Considering that <a href="http://python.org">Python</a> is my programming language I learned first, you
can understand why I get a bit annoyed when I&rsquo;m reading other language I&rsquo;m
not so familiar with, and names just pop up in scope without knowing where
they come from. And no, I don&rsquo;t want to use <a href="https://en.wikipedia.org/wiki/Ctags">ctags</a> or a full blown IDE
every time I&rsquo;m reading casually some code on the GitHub.</p>

<p>So then, why <a href="http://haskell.org">Haskell</a>, a language with such a great reputation for being
so well designed, doesn&rsquo;t follow these <a href="http://python.org">Python</a> principles, which look so
advantageously obvious? To be fair with <a href="http://haskell.org">Haskell</a>, we have to understand
that the class system in <a href="http://python.org">Python</a> is frequently <em>(ab)</em>used<sup id="fnref:2"><a href="#fn:2" rel="footnote">2</a></sup> just for
organizational purposes. <a href="http://haskell.org">Haskell</a>, by being a <a href="https://en.wikipedia.org/wiki/Pure_functional_language">pure functional
programming language</a>, doesn&rsquo;t add all the cruft of <a href="https://en.wikipedia.org/wiki/Class_(computer_programming)">OOP classes</a> just to
deal with this issue. Instead, it uses a very limited module system which
could be argued is a weakness of the language, but I believe it fits
nicely with the unofficial <a href="http://haskell.org">Haskell</a> slogan of <a href="http://www.reddit.com/r/programming/comments/77z8h/avoid_success_at_all_costs_the_unofficial_slogan/"><em>avoid success at all
costs</em></a>.</p>

<p>From my understanding, this means that if there is not an optimal solution
for a core language feature, it&rsquo;s preferable to keep the bare minimum
everyone agrees on and don&rsquo;t try to impose a half-baked solution that will
have to be maintained forever for legacy reasons. Taking this into
account, I&rsquo;d rather have a dumb module system easy to understand, than
having to deal forever with the complexity of historical design
accidents.<sup id="fnref:3"><a href="#fn:3" rel="footnote">3</a></sup></p>

<p>So in <a href="http://haskell.org">Haskell</a> we have to bite the bullet and accept that the imports
lists are going to be quite complex, and making absolutely every import
explicit like in <a href="http://python.org">Python</a> would be too cumbersome on the programmer who is
coding, so we have to reach some kind of trade-off between explicitness
for the reader vs convenience for the writer.</p>

<h3>Internal imports</h3>

<p>A popular style recommendation like <a href="https://github.com/tibbe/haskell-style-guide/blob/master/haskell-style.md#imports">the one from Johan Tibell</a> is to import explicitly everything outside the package, and
make internal imports implicit.</p>

<p>I consider Tibell&rsquo;s way a good rule to follow for most projects. It&rsquo;s a
good compromise because when reading a module from a givne package, it&rsquo;s
reasonable to assume the rest of modules of such package are usually nearby.</p>

<p>The other popular way <a href="https://ghc.haskell.org/trac/ghc/wiki/Commentary/CodingStyle#ExportsandImports">recommended in GHC</a> is to make
everything implicit. Breaking Tibell&rsquo;s rule in the case of GHC may be
understandable because in a project as large as <a href="https://www.haskell.org/ghc">GHC</a>, the import lists
would tend to be quite complex. I&rsquo;d also assume anyone trying to hack on
<a href="https://www.haskell.org/ghc">GHC</a> is above beginner&rsquo;s level and should be familiar with internals of the
project. But for most projects, I think <a href="https://github.com/tibbe/haskell-style-guide/blob/master/haskell-style.md#imports">Tibell&rsquo;s
recommendation</a> is a good default.</p>

<p>It could be argued that if there are many internal modules being imported
in the same module, it could become difficult to follow from which module
comes each name. It&rsquo;s true that this sometimes happens, but most of the
time I&rsquo;d attribute to a <a href="https://en.wikipedia.org/wiki/Code_smell">smell</a>. When this happens, I&rsquo;d look
for the following:</p>

<ul>
<li><em>Are modules not modular enough?</em> For good modularity the
communication between them should be as minimal as possible. Perhaps
the code needs to be rearranged in entirely different modules to
allow better separation of concerns.</li>
<li><em>Is the package too large?</em> Maybe it&rsquo;s time to separate the packages in
more subpackages.</li>
<li><em>Are you always importing a group of modules that somehow can be
logically grouped together?</em> All these modules could be consolidated in
a single module that just re-exports everything for the module group.
This, in fact, a very used pattern in <a href="http://haskell.org">Haskell</a> for code organization.</li>
</ul>


<p>The only exception to external explicit importing is <code>Prelude</code>, which is
almost always implicitly imported. <code>Prelude</code> is the closest you get to
<code>built-ins</code> in <a href="http://haskell.org">Haskell</a>.</p>

<p>Whenever I have some name clash with a <code>Prelude</code> name I don&rsquo;t hesitate to
hide the <code>Prelude</code> version if the context makes it clear that the imported
name is not the same as the one in <code>Prelude</code>. For example, I&rsquo;d hide the
<code>Prelude.span</code>, if I&rsquo;m not using it and if the imported <code>span</code> deals, for
example, with an span HTML element. But I wouldn&rsquo;t hide
<code>Prelude.writeFile</code> for <code>Data.Bytestring.writeFile</code> because it&rsquo;d be
misleading. In case of not hiding, I&rsquo;d use a qualified import, but I&rsquo;ll
comment more about them below.</p>

<p>Some people also give the <code>built-in</code> status to other very frequently used
modules such as <code>Control.Monad</code> or <code>Data.Monoid</code> in the <a href="http://hackage.haskell.org/package/base"><code>base</code>
package</a>. Even admitting that anyone with some experience with
<a href="http://haskell.org">Haskell</a> wouldn&rsquo;t have any trouble with these imports being implicit, I
still import them explicitly. I consider that, for experienced programmers
who are not familiar with Haskell, the names in <code>Prelude</code> are enough to
keep in mind, so, in my opinion, asking to memorize more modules  rises
too much the barrier of entry. I suffered this myself when learning
<a href="http://haskell.org">Haskell</a> for the first time, so I swore to myself I wouldn&rsquo;t do it in the
future.</p>

<h3>Constructors</h3>

<p>The usual convention for importing type constructors is to import them
implicitly using the <code>(..)</code> notation, but I don&rsquo;t follow this convention
because if many type constructors are brought into scope, we have the same
problem as with the scope of functions.</p>

<p>I only use <code>A(..)</code> if there is only a constructor for type <code>A</code> and it&rsquo;s
named <code>A</code> as well, which is the usual convention. If that&rsquo;s not the case I
also import the single constructor explicitly.<sup id="fnref:4"><a href="#fn:4" rel="footnote">4</a></sup></p>

<h3>Qualified imports</h3>

<p>They are frequently cited as the solution to module organization. However
I&rsquo;m uneasy about them and try to use them the least I can.</p>

<h4>Maintainability</h4>

<p>When there is a very long list of imports it&rsquo;s often argued that it&rsquo;s
better for maintainability to just use a single qualified import,
otherwise it&rsquo;s too much work to change the list of imports anytime there
is an API change in an external module. But I think it&rsquo;s the other way
around, maintaining that list makes sure you are using the API properly,
and if you get an error when upgrading the API, you are more likely to get
an import error which can be easily spotted. On the other hand, with a
qualified import, the module being upgraded can inadvertently introduce
names in scope provoking clash errors which may be harder to debug.</p>

<p>It&rsquo;s true that it&rsquo;s a bit extra effort to be constantly maintaining a long
list of imports, but with a decent code editor it shouldn&rsquo;t be too much of
a problem. I usually toggle between implicit and explicit imports while
finding out a good solution to some code I&rsquo;m writing, when I&rsquo;m satisfied I
make sure everything is exported explicitly again.</p>

<h4><a href="https://en.wikipedia.org/wiki/Word_search">Letter soup</a></h4>

<p>It&rsquo;s quite usual to find qualified imports with a capital letter like:
<code>import qualified Data.ByteString as B</code> or <code>import qualified
Data.ByteString as S</code> or <code>import qualified Data.ByteString.Lazy as B</code> or
<code>import Data.Binary as B</code>&hellip; you get where I&rsquo;m going.</p>

<p>The problem with qualified names with just a few characters, it&rsquo;s that the
chance of clashing is very high, so the same qualified import ends up with
different letters depending on the module, something I find confusing,
specially when you get used to associate a particular character to a
particular module. Aside of this, I don&rsquo;t find aesthetically pleasing to
read all over the code single capital letters followed by some function,
but this may be just me.</p>

<p>There are exceptions to this recommendation, of course, which I&rsquo;ll explain
below.</p>

<h4>Verbosity</h4>

<p>One obvious solution to the problem described below is to not use short
qualified names but full words like <code>ByteString</code> instead of <code>B</code>, <code>Binary</code>
instead of <code>B</code> or <code>Text</code> instead of <code>T</code>. But then, what happens when you
have a module using everywhere <code>Data.ByteString</code> and
<code>Data.ByteString.Lazy</code>? Do you write prepend every function with
<code>ByteString</code> an <code>ByteStringLazy</code>? Common sense would tell us that this is
too verbose, specially for a language like <a href="http://haskell.org">Haskell</a> where terseness is
one of its most touted features. I&rsquo;ll explain when to use long names for
qualified imports below.</p>

<h4>Import list as an introduction</h4>

<p>When I&rsquo;m opening a module, I like going through the list of imports to
prepare my mind for the context of the module. When I find something like
<code>import qualified Data.Binary as Binary</code>, the first thing I think to
myself is: <em>is this module going use just one function from <code>Binary</code> or is it
going to use many of them?</em>. I know I can have a quick glance at the rest
of the module to get an idea, but this adds just more friction for cases
where, for example, I want to quickly navigate through all the modules of
a package in order to get quick overview.</p>

<p>That&rsquo;s why I prefer to have explicit lists, even when qualified imports
are being used. For such case, however, I acknowledge that I don&rsquo;t always
follow my own advice. I consider them nice to have, not very important.</p>

<h4>When qualified imports are OK</h4>

<p>The first broad scenario has to do with <code>Prelude</code>. Is the module being
imported going to clash with several other functions from <code>Prelude</code> that
I&rsquo;ll also be using or are difficult to distinguish by context? If this is
the case then I&rsquo;ll try to use a qualified import, specially when the
original author recommends it. The usual suspects in this list are imports
like <code>Data.Foldable</code> (<code>F</code>), <code>Data.Traversable</code> (<code>T</code>), <code>bytestring</code> (<code>B</code>,
<code>B8</code>, <code>L</code>, <code>L8</code>), <code>text</code> (<code>T</code>, <code>TIO</code>, <code>TL</code>), <code>containers</code> (<code>Map</code>, <code>Set</code>),
<code>pipes</code> (<code>P</code>, <code>PP</code>), etc. I try to follow the same letter convention
everywhere. But notice that if I know I won&rsquo;t use the <code>Prelude</code> version at
all and from the context it can be clearly distinguished that is not the
<code>Prelude</code> function, then I&rsquo;ll hide it as I explained above for the <code>span</code>
example. It&rsquo;s import to notice that for these packages, the types can be
usually imported unqualified without any issue.</p>

<p>The second scenario is when 2 imported modules clash with the same names.
In this case I&rsquo;d use qualified names for just the conflicting functions.
For example, <code>Binary.decode</code> and <code>Cereal.decode</code>. If the modules are the
usual candidates for single letter qualified names like like <code>bytestring</code>
and <code>text</code> I&rsquo;ll keep using the single letter, otherwise I&rsquo;d use a long
name.</p>

<p>There is one last case where using long qualified names would be OK with
me. For example, when the function uses a very vague name where it&rsquo;s
difficult to guess what&rsquo;s really about, it may be appropriate to prepend
it with the module name. For example, the <code>get</code> and <code>put</code> functions from
the <code>State</code> monad are much easier to identify when writing them as
<code>State.get</code> and <code>State.put</code>.</p>

<h2>Order of imports</h2>

<p>Some criteria for ordering imports is important because it makes it
possible to predict in which order modules appear. If you get used to
the same pattern of appearance, you can quickly find what&rsquo;s in the module
and what is not.</p>

<h3>Modules</h3>

<p>In <a href="https://github.com/tibbe/haskell-style-guide/blob/master/haskell-style.md#imports">Tibell&rsquo;s guide</a> it&rsquo;s recommended to group the
imports by standard library, third party software, and local package
imports. I follow this too, but, firstly, I distinguish in the standard
library the modules coming from <a href="http://hackage.haskell.org/package/base"><code>base</code></a>, <a href="https://www.haskell.org/ghc">GHC</a> libraries and packages
belonging to the <a href="http://www.haskell.org/platform">Haskell Platform</a>. Secondly, where Tibell recommends to
sort alphabetically between groups, I try to follow the rule of which
package is (or should be) most frequently used overall, and within each
package which module is most prominent. When this is not obvious then
alphabetical sorting should be used.</p>

<p>Of course, there is no precise way to define which package is more
frequently used. I&rsquo;d leave this entirely to your own personal experience
but you can get some idea by checking the <a href="http://packdeps.haskellers.com">reverse dependencies</a> of a
package, or the downloads in <a href="http://hackage.haskell.org">Hackage</a>, or <code>grep &lt;module&gt; | wc</code> a bunch
popular packages.</p>

<p>The main purpose of this rule is to try to make it easier to skim through
the most usual imports first and focus at the end on the rare module
exports. This is also important when trying to minimize dependencies, you
can quickly spot which ones you can try to drop.</p>

<p>For example:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
</pre></td><td class='code'><pre><code class='haskell'><span class='line'><span class="kr">import</span> <span class="nn">Control.Applicative</span> <span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Control.Monad</span> <span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Data.Monoid</span> <span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Data.Foldable</span> <span class="p">(</span><span class="o">...</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>Here, I put <code>Applicative</code> before <code>Monad</code> because even though, in practice,
it might be less used, my own judgement tells me it&rsquo;s more general than a
<code>Monad</code>, so it <em>should</em> be more frequent. Between the <code>Control</code> and the
<code>Data</code> module names I choose to sort them alphabetically, I don&rsquo;t know
which one is most usual. Whatever you decide, it&rsquo;s always better to stick
with the same preference everywhere.</p>

<p>Notice also that I don&rsquo;t take into account the length of the export list
or how frequent are the functions appear in the module itself. That would,
perhaps, be valid criteria but they wouldn&rsquo;t make the import list very
repeatable.</p>

<h3>Types and functions</h3>

<p>I group first the <code>Types</code> with their constructors; next, <a href="http://www.haskell.org/haskellwiki/Infix_operator">infix functions</a>
and lastly, all other functions.</p>

<p>When there is a mixture of qualified and unqualified imports for the same
import I still group them together, with the unqualified names going
first. I don&rsquo;t like having the qualified imports and unqualified imports
grouped separately because usually I find myself moving back and forth
some functions between them.</p>

<p>There is an exception here though. When the module being imported is
re-exporting names defined in other modules I then group them after the
ones which are defined directly in the imported module.</p>

<h2>Formatting</h2>

<p>I use multiple lines when the list of imports overpasses the specified
text width and a indentation of 2 spaces when happening.</p>

<p>I also add spaces to module lists but not for constructors, just to give a
quick hint that they are constructors. For example:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
</pre></td><td class='code'><pre><code class='haskell'><span class='line'><span class="kr">import</span> <span class="nn">module1</span> <span class="p">(</span><span class="kt">A</span><span class="p">(</span><span class="kt">A1</span><span class="p">,</span><span class="kt">A2</span><span class="p">),</span> <span class="kt">B</span><span class="p">,</span> <span class="p">(</span><span class="o">-|-</span><span class="p">),</span> <span class="n">func1</span><span class="p">,</span> <span class="n">func2</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>&hellip; unless the constructors are multiline, which is not that frequent though:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
</pre></td><td class='code'><pre><code class='haskell'><span class='line'><span class="kr">import</span> <span class="nn">module</span>
</span><span class='line'>  <span class="p">(</span> <span class="kt">A</span> <span class="p">(</span> <span class="kt">A1</span>
</span><span class='line'>      <span class="p">,</span> <span class="kt">A2</span>
</span><span class='line'>      <span class="p">,</span> <span class="kt">AN</span>
</span><span class='line'>      <span class="p">)</span>
</span><span class='line'>  <span class="p">,</span> <span class="kt">B</span>
</span><span class='line'>  <span class="p">,</span> <span class="n">func1</span>
</span><span class='line'>  <span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<p>I know of editing tools to make vertical alignment very simple, but,
personally, I don&rsquo;t find vertical alignment improving that much in
readability. The words in the same line tend to be too separated.</p>

<h2>Canonical example</h2>

<p>The import style followed by <a href="http://haskell-distributed.github.io">Cloud Haskell</a> packages aligns quite well
with my particular style. This is a modified version taken from
<a href="https://github.com/haskell-distributed/distributed-process/blob/master/src/Control/Distributed/Process/Node.hs#L16"><code>Control.Distributed.Process.Node</code></a>: <sup id="fnref:5"><a href="#fn:5" rel="footnote">5</a></sup></p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
<span class='line-number'>12</span>
<span class='line-number'>13</span>
<span class='line-number'>14</span>
<span class='line-number'>15</span>
<span class='line-number'>16</span>
<span class='line-number'>17</span>
<span class='line-number'>18</span>
<span class='line-number'>19</span>
<span class='line-number'>20</span>
<span class='line-number'>21</span>
<span class='line-number'>22</span>
<span class='line-number'>23</span>
<span class='line-number'>24</span>
<span class='line-number'>25</span>
<span class='line-number'>26</span>
<span class='line-number'>27</span>
<span class='line-number'>28</span>
<span class='line-number'>29</span>
<span class='line-number'>30</span>
<span class='line-number'>31</span>
<span class='line-number'>32</span>
<span class='line-number'>33</span>
<span class='line-number'>34</span>
<span class='line-number'>35</span>
<span class='line-number'>36</span>
<span class='line-number'>37</span>
<span class='line-number'>38</span>
<span class='line-number'>39</span>
<span class='line-number'>40</span>
<span class='line-number'>41</span>
<span class='line-number'>42</span>
<span class='line-number'>43</span>
<span class='line-number'>44</span>
<span class='line-number'>45</span>
<span class='line-number'>46</span>
<span class='line-number'>47</span>
<span class='line-number'>48</span>
<span class='line-number'>49</span>
<span class='line-number'>50</span>
<span class='line-number'>51</span>
<span class='line-number'>52</span>
<span class='line-number'>53</span>
<span class='line-number'>54</span>
<span class='line-number'>55</span>
<span class='line-number'>56</span>
<span class='line-number'>57</span>
<span class='line-number'>58</span>
</pre></td><td class='code'><pre><code class='haskell'><span class='line'><span class="kr">import</span> <span class="nn">Prelude</span> <span class="k">hiding</span> <span class="p">(</span><span class="nf">catch</span><span class="p">)</span>
</span><span class='line'><span class="c1">-- &#39;base&#39; imports</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Control.Category</span> <span class="p">((</span><span class="o">&gt;&gt;&gt;</span><span class="p">))</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Control.Applicative</span> <span class="p">((</span><span class="o">&lt;$&gt;</span><span class="p">))</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Control.Monad</span> <span class="p">(</span><span class="nf">void</span><span class="p">,</span> <span class="nf">when</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Control.Concurrent</span> <span class="p">(</span><span class="nf">forkIO</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Data.Foldable</span> <span class="p">(</span><span class="nf">forM_</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Data.Maybe</span> <span class="p">(</span><span class="nf">isJust</span><span class="p">,</span> <span class="nf">isNothing</span><span class="p">,</span> <span class="nf">catMaybes</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Data.Typeable</span> <span class="p">(</span><span class="kt">Typeable</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Control.Exception</span> <span class="p">(</span><span class="nf">throwIO</span><span class="p">,</span> <span class="kt">SomeException</span><span class="p">,</span> <span class="kt">Exception</span><span class="p">,</span> <span class="nf">throwTo</span><span class="p">,</span> <span class="nf">catch</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">System.IO</span> <span class="p">(</span><span class="nf">fixIO</span><span class="p">,</span> <span class="nf">hPutStrLn</span><span class="p">,</span> <span class="nf">stderr</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">System.Mem.Weak</span> <span class="p">(</span><span class="kt">Weak</span><span class="p">,</span> <span class="nf">deRefWeak</span><span class="p">)</span>
</span><span class='line'><span class="c1">-- imports from the rest of the Haskell Platform</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Control.Monad.IO.Class</span> <span class="p">(</span><span class="kt">MonadIO</span><span class="p">,</span> <span class="nf">liftIO</span><span class="p">)</span> <span class="c1">-- &#39;transformers&#39; package</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Control.Monad.State.Strict</span> <span class="p">(</span><span class="kt">MonadState</span><span class="p">,</span> <span class="kt">StateT</span><span class="p">,</span> <span class="nf">evalStateT</span><span class="p">,</span> <span class="nf">gets</span><span class="p">)</span>
</span><span class='line'><span class="c1">-- these are likely to clash with local bindings</span>
</span><span class='line'><span class="kr">import</span> <span class="k">qualified</span> <span class="nn">Control.Monad.State.Strict</span> <span class="k">as</span> <span class="n">StateT</span> <span class="p">(</span><span class="n">get</span><span class="p">,</span> <span class="n">put</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Control.Monad.Reader</span> <span class="p">(</span><span class="kt">MonadReader</span><span class="p">,</span> <span class="kt">ReaderT</span><span class="p">,</span> <span class="nf">runReaderT</span><span class="p">,</span> <span class="nf">ask</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Data.ByteString.Lazy</span> <span class="p">(</span><span class="nf">fromChunks</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Data.Map</span> <span class="p">(</span><span class="kt">Map</span><span class="p">,</span> <span class="nf">partitionWithKey</span><span class="p">,</span> <span class="nf">filterWithKey</span><span class="p">,</span> <span class="nf">foldlWithKey</span><span class="p">)</span>
</span><span class='line'><span class="c1">-- these are likely to clash with other names</span>
</span><span class='line'><span class="kr">import</span> <span class="k">qualified</span> <span class="nn">Data.Map</span> <span class="k">as</span> <span class="n">Map</span>
</span><span class='line'>  <span class="p">(</span> <span class="n">empty</span>
</span><span class='line'>  <span class="p">,</span> <span class="n">toList</span>
</span><span class='line'>  <span class="p">,</span> <span class="n">fromList</span>
</span><span class='line'>  <span class="p">,</span> <span class="n">filter</span>
</span><span class='line'>  <span class="p">,</span> <span class="n">elems</span>
</span><span class='line'>  <span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Data.Set</span> <span class="p">(</span><span class="kt">Set</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="k">qualified</span> <span class="nn">Data.Set</span> <span class="k">as</span> <span class="n">Set</span>
</span><span class='line'>  <span class="p">(</span> <span class="n">empty</span>
</span><span class='line'>  <span class="p">,</span> <span class="n">insert</span>
</span><span class='line'>  <span class="p">,</span> <span class="n">delete</span>
</span><span class='line'>  <span class="p">,</span> <span class="n">member</span>
</span><span class='line'>  <span class="p">,</span> <span class="n">toList</span>
</span><span class='line'>  <span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Data.Binary</span> <span class="p">(</span><span class="nf">decode</span><span class="p">)</span>
</span><span class='line'><span class="kr">import</span> <span class="nn">Network.Transport</span>
</span><span class='line'>  <span class="p">(</span> <span class="kt">Transport</span>
</span><span class='line'>  <span class="p">,</span> <span class="kt">EndPoint</span>
</span><span class='line'>    <span class="c1">-- Assuming there is only the &#39;Event&#39; constructor</span>
</span><span class='line'>  <span class="p">,</span> <span class="kt">Event</span><span class="p">(</span><span class="o">..</span><span class="p">)</span>
</span><span class='line'>  <span class="p">,</span> <span class="kt">EventErrorCode</span><span class="p">(</span><span class="o">..</span><span class="p">)</span>
</span><span class='line'>  <span class="p">,</span> <span class="kt">TransportError</span><span class="p">(</span><span class="o">..</span><span class="p">)</span>
</span><span class='line'>  <span class="p">,</span> <span class="kt">ConnectionId</span>
</span><span class='line'>  <span class="p">,</span> <span class="kt">Connection</span>
</span><span class='line'>  <span class="p">,</span> <span class="nf">newEndPoint</span>
</span><span class='line'>  <span class="p">,</span> <span class="nf">closeEndPoint</span>
</span><span class='line'>    <span class="c1">-- This would re-exports in &#39;Network.transport&#39;</span>
</span><span class='line'>  <span class="p">,</span> <span class="kt">EndPointAddress</span>
</span><span class='line'>  <span class="p">,</span> <span class="kt">Reliability</span><span class="p">(</span><span class="kt">ReliableOrdered</span><span class="p">)</span>
</span><span class='line'>  <span class="p">)</span>
</span><span class='line'><span class="c1">-- qualified because names are too vague</span>
</span><span class='line'><span class="kr">import</span> <span class="k">qualified</span> <span class="nn">Network.Transport</span> <span class="k">as</span> <span class="n">NT</span>
</span><span class='line'>  <span class="p">(</span> <span class="n">receive</span>
</span><span class='line'>  <span class="p">,</span> <span class="n">address</span>
</span><span class='line'>  <span class="p">,</span> <span class="n">close</span>
</span><span class='line'>  <span class="p">)</span>
</span></code></pre></td></tr></table></div></figure>


<h2>Conclusion</h2>

<p>I was keeping all these rules in my head until after a constructive
discussion with <a href="http://ro-che.info">Roman Cheplyaka</a> about the topic, I decided to write them
down in a post that I could use as a reference for myself and for my
colleagues. But, by no means, I&rsquo;m trying to claim my style is better than
any other, this is what I follow as of today, and will surely evolve as my
experience in <a href="http://haskell.org">Haskell</a> grows.</p>

<p>If you just got into <a href="http://haskell.org">Haskell</a> and find yourself trying to follow some
consistent importing style through your code, but lack the hands-on
experience to assess what&rsquo;s best for you (and if you are control freak
like me), you might want to follow this blindly until you have more skin
in the game and can make a more confident decision of what style you
prefer to stick with. One advantage of this style is that, even if other
Haskell programmers don&rsquo;t like it because of its extra editing work, it&rsquo;s
still easily readable.</p>

<p>But remember one thing, all this doesn&rsquo;t matter if a project already
follows its own style. Consistency is always better for readability, even
if you don&rsquo;t like the style. So always trust more your common sense than
any styling guide for which it&rsquo;s impossible to define every scenario you
may encounter in real life.</p>

<!---
vim: textwidth=74
-->

<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>For code contributions it&rsquo;s easy, just follow what the original author is already doing.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
<li id="fn:2">
<p>This could be arguable considered the main use case for OOP in most languages.<a href="#fnref:2" rev="footnote">&#8617;</a></p></li>
<li id="fn:3">
<p>There is <a href="http://plv.mpi-sws.org/backpack">some research</a> going on but still a long way to reach consensus.<a href="#fnref:3" rev="footnote">&#8617;</a></p></li>
<li id="fn:4">
<p>For exports I think it&rsquo;s alright to always use <code>(..)</code>, the constructors are in the same module.<a href="#fnref:4" rev="footnote">&#8617;</a></p></li>
<li id="fn:5">
<p>My modifications will surely break the code, this is just a sample demonstration.<a href="#fnref:5" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Improving readability with the Maybe Foldable instance]]></title>
    <link href="http://dannynavarro.net/2014/03/12/improving-readability-with-the-maybe-foldable-instance/"/>
    <updated>2014-03-12T12:00:00+01:00</updated>
    <id>http://dannynavarro.net/2014/03/12/improving-readability-with-the-maybe-foldable-instance</id>
    <content type="html"><![CDATA[<p>One recommendation you often hear when reaching an acceptable level of basic
Haskell is to make your code more polymorphic. The Haskell <a href="http://hackage.haskell.org/package/base/docs/Prelude.html"><code>Prelude</code></a> is
heavily biased towards lists, so an immediate gain in polymorphism is to make
your code work not only for lists but for any instance of <a href="http://hackage.haskell.org/package/base/docs/Data-Traversable.html"><code>Traversable</code></a> or
<a href="http://hackage.haskell.org/package/base/docs/Data-Foldable.html"><code>Foldable</code></a>.<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup></p>

<p>Since a Haskell list is an instance of <a href="http://hackage.haskell.org/package/base/docs/Data-Traversable.html"><code>Traversable</code></a> and <a href="http://hackage.haskell.org/package/base/docs/Data-Foldable.html"><code>Foldable</code></a>, we can
still operate as usual on lists with the new polymorphic code:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
</pre></td><td class='code'><pre><code class='haskell'><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="kr">import</span> <span class="k">qualified</span> <span class="nn">Data.Foldable</span> <span class="k">as</span> <span class="n">F</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="n">mapM_</span> <span class="n">print</span> <span class="p">[</span><span class="n">&#39;a&#39;</span><span class="o">..</span><span class="n">&#39;c&#39;</span><span class="p">]</span>
</span><span class='line'><span class="n">&#39;a&#39;</span>
</span><span class='line'><span class="n">&#39;b&#39;</span>
</span><span class='line'><span class="n">&#39;c&#39;</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="kt">F</span><span class="o">.</span><span class="n">traverse_</span> <span class="n">print</span> <span class="p">[</span><span class="n">&#39;a&#39;</span><span class="o">..</span><span class="n">&#39;c&#39;</span><span class="p">]</span>
</span><span class='line'><span class="n">&#39;a&#39;</span>
</span><span class='line'><span class="n">&#39;b&#39;</span>
</span><span class='line'><span class="n">&#39;c&#39;</span>
</span></code></pre></td></tr></table></div></figure>


<p>Notice here that we&rsquo;ve gained the extra advantage of being able to use <code>Applicative</code>
instead of <code>Monad</code>. Here, we don&rsquo;t need the extra power of <code>Monad</code>, and the
<code>Applicative</code>, by being weaker, is also more generalizable.</p>

<p>But aside of lists, there is another instance of <code>Traversable</code>/<code>Foldable</code>
defined by default for us: <code>Maybe</code>. You could think of a <code>Maybe</code> as a list of 1
or 0 elements, so when you are traversing it you either do something with the
element if present or do the default <code>Applicative</code>/<code>Monad</code> action (<code>pure</code> and
<code>return</code> respectively) if not present. How is this useful then? Have you ever
found yourself writing case expressions like this?</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
<span class='line-number'>7</span>
<span class='line-number'>8</span>
<span class='line-number'>9</span>
<span class='line-number'>10</span>
<span class='line-number'>11</span>
</pre></td><td class='code'><pre><code class='haskell'><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="kt">:</span><span class="p">{</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="kr">let</span> <span class="n">printM</span> <span class="n">m</span> <span class="ow">=</span> <span class="kr">case</span> <span class="n">m</span> <span class="kr">of</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span>                     <span class="kt">Just</span> <span class="n">n</span>  <span class="ow">-&gt;</span> <span class="n">print</span> <span class="n">n</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span>                     <span class="kt">Nothing</span> <span class="ow">-&gt;</span> <span class="n">return</span> <span class="nb">()</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="kt">:</span><span class="p">}</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="kr">let</span> <span class="n">m1</span> <span class="ow">=</span> <span class="kt">Just</span> <span class="mi">1</span> <span class="ow">::</span> <span class="kt">Maybe</span> <span class="kt">Int</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="kr">let</span> <span class="n">m_</span> <span class="ow">=</span> <span class="kt">Nothing</span> <span class="ow">::</span> <span class="kt">Maybe</span> <span class="kt">Int</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="n">printM</span> <span class="n">m1</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="mi">1</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="n">printM</span> <span class="n">m_</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>The function <a href="http://hackage.haskell.org/package/base-4.6.0.1/docs/Data-Maybe.html#v:maybe"><code>maybe</code></a> would improve a bit, syntactically speaking: <code>maybe
(return ()) print</code>.</p>

<p>Maybe it&rsquo;s just me, but that <code>return ()</code> <a href="https://en.wikipedia.org/wiki/Code_smell">smells</a> too much of a default
behavior to me. Somehow, there should be a way to avoid it. Well, here is where
<a href="http://hackage.haskell.org/package/base/docs/Data-Foldable.html"><code>Foldable</code></a> instance of <code>Maybe</code> comes handy:</p>

<figure class='code'><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class='line-number'>1</span>
<span class='line-number'>2</span>
<span class='line-number'>3</span>
<span class='line-number'>4</span>
<span class='line-number'>5</span>
<span class='line-number'>6</span>
</pre></td><td class='code'><pre><code class='haskell'><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="kt">:</span><span class="n">set</span> <span class="o">-</span><span class="kt">XScopedTypeVariables</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="kr">let</span> <span class="n">printM&#39;</span> <span class="ow">::</span> <span class="kt">Maybe</span> <span class="kt">Int</span> <span class="ow">-&gt;</span> <span class="kt">IO</span> <span class="nb">()</span> <span class="ow">=</span> <span class="kt">F</span><span class="o">.</span><span class="n">traverse_</span> <span class="n">print</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="n">printM&#39;</span> <span class="n">m1</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="mi">1</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span> <span class="n">printM&#39;</span> <span class="n">m_</span>
</span><span class='line'><span class="o">&gt;&gt;&gt;</span>
</span></code></pre></td></tr></table></div></figure>


<p>To be fair, for this trivial example, it would be a bit frivolous to use the
<code>Maybe</code> <code>Foldable</code> instance just to avoid the case expression, but when you are
in an intricate case expression ladder, this idiom can make your code much more
readable.</p>
<div class="footnotes">
<hr/>
<ol>
<li id="fn:1">
<p>Roughly speaking, the <code>Traversable</code> instance would be used for operations that do something on each element of the structure while maintaining same structure in the output. A <code>Foldable</code> instance would be used for collapsing the elements into anything else.<a href="#fnref:1" rev="footnote">&#8617;</a></p></li>
</ol>
</div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Migrating to Octopress]]></title>
    <link href="http://dannynavarro.net/2011/09/20/migrating-to-octopress/"/>
    <updated>2011-09-20T19:07:00+02:00</updated>
    <id>http://dannynavarro.net/2011/09/20/migrating-to-octopress</id>
    <content type="html"><![CDATA[<p>I finally found some time to migrate my blog to <a href="http://wordpress.com/">Octopress</a> from
<a href="http://octopress.org/">Wordpress.com</a>. The critical reason to migrate from Wordpress has
been the support for nice code syntax highlighting, something I
couldn&rsquo;t have wordpress.com, at least for free. I know there are very
nice wordpress plugins for syntax highlighting but in order to use
them I would have to host it myself. I don&rsquo;t want to go through the
hassle of maintaining a typical PHP/MySQL stack or to be worried about
being <a href="http://en.wikipedia.org/wiki/Slashdotted"><em>slashdotted</em></a>.</p>

<p>Having worked with an excellent documentation tool like <a href="http://sphinx.pocoo.org/">Sphinx</a>, I
started looking to static blog generators meant. It turned out that
<a href="http://blog.manuelviera.es/">Manu Viera</a>, a colleague working at <a href="http://www.yaco.es/">Yaco</a> with me, shared the
same itch and had already looked several static web generators in
Python, which is our main language at <a href="http://www.yaco.es/">Yaco</a>. Manu found
<a href="https://github.com/ametaireau/pelican">pelican</a> the best candidate but still I found it a bit immature,
not something like something like <a href="https://github.com/mojombo/jekyll">Jekyll</a>.</p>

<p>Then I found <a href="http://wordpress.com/">Octopress</a>, a framework built on top of <a href="https://github.com/mojombo/jekyll">Jekyll</a>
with <a href="http://octopress.org/docs/plugins/">several plugins</a>, including syntax highlighting or automatic
support for <a href="http://disqus.com/">disqus</a> comments.</p>

<p>The migration from wordpress was not too painful. I used the default
Jekyll script to import wordpress posts and disqus importer for the
comments.  After some sed commands I got nice markdown formatted
scripts.</p>

<p>I had some trouble in the beginning configuring an isolated Ruby
runtime in <a href="http://archlinux.org/">Arch Linux</a> just for Octopress but after discovering
<a href="https://github.com/sstephenson/rbenv">rbenv</a>, everything went smooth. (I prefer rbenv instead RVM with
rbenv I know at any moment what it&rsquo;s doing).</p>

<p>Deploying an Octopress generated site to <a href="http://pages.github.com/">github pages</a> is as
<a href="http://octopress.org/docs/deploying/index.html">easy</a> as pie.</p>

<p>Aside of nice Python syntax highlighting now I have some extra
advantages I didn&rsquo;t have with wordpress.com:</p>

<ul>
<li><p>Markdown syntax when writing my posts.</p></li>
<li><p>I can use the best text editor to mankind: <a href="http://www.vim.org/">vim</a> :P</p></li>
<li><p>My blog data becomes more manageable. If at some point I don&rsquo;t want
to host it github, I could just to push it somewhere else with no
modification.</p></li>
<li><p>I got a very nice default theme for free, that aside of looking
good, it&rsquo;s also very easy to tweak and maintain.</p></li>
<li><p>Now I have a good excuse to learn Ruby outside of RoR influence.
Ruby is one of those languages I wish I would be better at, even if
Python remains my main working language.</p></li>
</ul>


<p>In any case, I must say the service provided by wordpress.com has been
quite good but this one of those cases where you have to say: <em>‚ÄúSorry,
it&rsquo;s not you, it&rsquo;s just me‚Äù.</em></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using custom events in Pyramid]]></title>
    <link href="http://dannynavarro.net/2011/06/12/using-custom-events-in-pyramid/"/>
    <updated>2011-06-12T00:00:00+02:00</updated>
    <id>http://dannynavarro.net/2011/06/12/using-custom-events-in-pyramid</id>
    <content type="html"><![CDATA[<p><a href="http://docs.pylonsproject.org/docs/pyramid.html">Pyramid</a> is a <a href="http://webpython.codepoint.net/wsgi_tutorial">WSGI</a>¬†application framework that primarily follows a<a href="http://docs.pylonsproject.org/projects/pyramid/1.0/narr/router.html">¬†request-response mechanism</a>. However, if you need to work with events you can still <a href="http://docs.pylonsproject.org/projects/pyramid/1.0/narr/events.html">use them</a>. It comes with <a href="http://docs.pylonsproject.org/projects/pyramid/1.0/api/events.html#event-types">some default event types</a> that are emitted implicitely by Pyramid as long as you have a subscriber for them. For most applications the default event types are enough, but what if you want to write your custom event type and emit it¬†explicitly¬†from your code?¬†It turns out that the <a href="http://docs.pylonsproject.org/projects/pyramid/1.0/glossary.html#term-application-registry">application registry</a>¬†that Pyramid uses by default comes with a handy <a href="https://github.com/Pylons/pyramid/blob/master/pyramid/registry.py#L36"><em>notify</em> method</a>.¬†Pyramid <a href="https://github.com/Pylons/pyramid/blob/master/pyramid/router.py#L77">uses this method internally</a> ¬†for its default events. Here is how you would take advantage of it:</p>

<pre>from pyramid.events import subscriber

class MyCustomEventType(object):
    def __init__(self, msg):
        self.msg = msg

@subscriber(MyCustomEventType)
def my_subscriber(event):
    print(event.msg)

def my_view(request):
    request.registry.notify(MyCustomEventType("Here it comes"))
    return {}
</pre>


<p>When running the application, every time a request goes through¬†<em>my_view,</em>¬†an event with a message is emitted, in this case, &ldquo;Here it comes&rdquo;. The subscriber then handles the event by printing the message, but it could do anything you want.</p>

<p>Notice that I&rsquo;m using a <a href="http://docs.pylonsproject.org/projects/pyramid/1.0/narr/events.html#configuring-an-event-listener-using-a-decorator">decorator to hook</a>¬†<em>my_subscriber</em>. In order for the decorator to work you have to make sure you <a href="http://docs.pylonsproject.org/projects/pyramid/1.0/narr/configuration.html#configuration-decorations-and-code-scanning">call the <em>scan</em> method when configuring</a> the application.</p>

<p>Be aware though, that all these events are¬†synchronous because Pyramid is primarily a request-response framework, all the events emitted block until the subscribers are done. If you want non-blocking events in Pyramid you could spawn a process from the subscriber or come with <a href="http://blog.dannynavarro.net/2011/01/14/async-web-apps-with-pyramid/">some other solution</a>.</p>

<p>But the events in Pyramid are just another functionality that it offers. Pyramid is not a event-oriented framework, if you want to go all the way with async events you should look into¬†<a href="http://twistedmatrix.com/trac/">Twisted</a> or <a href="http://www.tornadoweb.org/">Tornado</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Why Arch Linux]]></title>
    <link href="http://dannynavarro.net/2011/05/21/why-arch-linux/"/>
    <updated>2011-05-21T00:00:00+02:00</updated>
    <id>http://dannynavarro.net/2011/05/21/why-arch-linux</id>
    <content type="html"><![CDATA[<p>I have been using <a href="http://www.archlinux.org/">Arch Linux</a> for 3 years now. I still use Debian and Ubuntu for the servers I administer but I acknowledge Arch Linux has taught many valuable lessons.</p>

<p>With Arch Linux there is very little in your system that you are not aware of. You have to configure everything yourself by editing config files. The process is not that hard because all those configuration files are meant to be tweaked. You also count with an <a href="https://wiki.archlinux.org">excellent wiki</a> to help you.</p>

<p>The <a href="https://wiki.archlinux.org/index.php/The_Arch_Way">Arch Linux philosophy</a>¬†doesn&rsquo;t try to shield the user from complexity with extra layers. Instead it focuses on making the direct configuration as simply as possible. For example, writing a proper boot script is much straightforward than in other distros. At the same time if you are not careful you have more chances of really screw things up everything.</p>

<p>Arch Linux aggressively updates from upstream sources. This has the advantage and disadvantages of being always in the bleeding-edge. I also like the idea of putting more¬†responsibility¬†about the stability of software in developers than in packagers, as long as you are aware of this as a user. As a user you have to assume the¬†responsibility¬†of being at the cutting-edge. Things may not go always smooth but you count with excellent tools to manage chaos.</p>

<p>That brings me to the real killer feature that makes Arch Linux shine over the rest: the packaging system.¬†<a href="https://wiki.archlinux.org/index.php/Pacman">Pacman</a>,¬†<a href="https://wiki.archlinux.org/index.php/ABS">ABS</a>, <a href="https://wiki.archlinux.org/index.php/AUR">AUR</a>, <a href="https://wiki.archlinux.org/index.php/Makepkg">makepkg</a>¬†and the¬†<a href="https://wiki.archlinux.org/index.php/PKGBUILD">PKGBUILD</a> format are just great. You usually don&rsquo;t have to mess with packaging that much, everything installs nicely and dependencies are correctly handled, specially if you stick to the official repository.</p>

<p>But if you don&rsquo;t like something about a package or need another version you have all the tools in place for the creation and¬†introspection of packages without disrupting pacman bookkeeping (pacman is the equivalent of dpkg/apt-get in Debian). ¬†Let me illustrate all this with something I had to deal with this week.</p>

<p>I decide to use¬†<a href="http://compass-style.org/blog/">Compass</a>¬†to make my stormy relationship with CSS smoother. Compass is a Ruby gem, the usual way to install gems is through Ruby packaging system but I don&rsquo;t want to mess with the Ruby libraries already installed in the system with pacman. If I install those gems as root pacman will not be able to keep track of them, everything could break in the future, and most importantly, without an easy solution.</p>

<p><a href="http://rhodesmill.org/brandon/2011/adding-compass/">A way</a> to deal with this issue is to install the Compass gem in some directory and handle the runtime somehow. You usually end up with a new runtime environment for each project you start. There are excellent tools to manage runtimes in Ruby like <a href="http://rake.rubyforge.org/">Rake</a>, but boy, I already have enough <a href="http://www.doughellmann.com/projects/virtualenvwrapper/">managing</a> my Python <a href="http://pypi.python.org/pypi/virtualenv">virtualenvs</a>.</p>

<p>I see that Compass is already in AUR. <a href="http://aur.archlinux.org/">AUR</a> is a very liberal package repository where anyone can upload source packages. When you install from AUR you usually have a review the PKGBUILD, the comments of other users and check how many users have voted the package to be included in official repositories. With tools like <a href="https://wiki.archlinux.org/index.php/Yaourt">yaourt</a>¬†the whole process is very smooth.</p>

<p>Alright, the ruby-compass PKGBUILD looks good to me so I install it.¬†Now compass is a good system¬†citizen¬†and can be updated, installed and uninstalled through pacman. Compass works as expected but it turns out that the most interesting feature I wanted to use in Compass is only available in the latest version of Compass, the version in AUR is not the latest one.</p>

<p>No problem, it&rsquo;ll probably be some version bumps and I&rsquo;ll be done. I download the PKGBUILD, bump the versions and build the package again but then I realize that the new version depends on new Ruby gems that are not in AUR.</p>

<p>At this point I would avoid getting into a dependency hell and go for Rake, but wait, I&rsquo;m using Arch Linux, let&rsquo;s see what happens if I continue with the Arch flow.</p>

<p>I take the PKGBUILD of Compass as a template, which is generic enough for any Ruby gem, and use them for the Ruby dependencies. I update¬†licences, versions checksums, build them and done, everything works. They are all coming from <a href="http://rubyforge.org/">rubyforge</a>¬†and follow the same building conventions, making my life¬†easy as a packager.</p>

<p>I upload the PKGBUILDs to AUR with just one <a href="https://bbs.archlinux.org/viewtopic.php?id=97137">burp</a> command. Now I can install the latest version of compass through pacman without any issue. I then send my modified version of PKGBUILD to the original Compass packager who updates it. That&rsquo;s it, now anyone can install the latest version of Compass with all its dependencies from AUR. I now can install Compass at home with just one command: just¬†<em>yaourt -Sy ruby-compass.</em></p>

<p>Now I just have to keep an eye in new updates on the dependencies I&rsquo;m now maintaining in AUR but rubyforge offers an excellent notification system for gem updates.</p>

<p>That&rsquo;s it.¬†The whole thing took less than 30 minutes.</p>

<p>I don&rsquo;t know if nowadays writing a DEB package spec is that hard, I acknowledge I never tried. The tutorials I found about them drove me away when I considered it some years ago.</p>

<p>It&rsquo;s not only the packaging format itself, there is also the community and policy aspects. Editing your PKGBUILDs is something that every Arch Linux user does. For AUR¬†there is very little regulating making the packaging smoother process at the expense of shifting the trust on the packages to the user. In general, most packages in AUR are good enough but for production machines I still value more the trust the Debian and Ubuntu package maintainers.</p>

<p>That&rsquo;s where open source community shines, you have many choices.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Commenting out in Chamaleon templates]]></title>
    <link href="http://dannynavarro.net/2011/05/18/commenting-out-in-chamaleon-templates/"/>
    <updated>2011-05-18T00:00:00+02:00</updated>
    <id>http://dannynavarro.net/2011/05/18/commenting-out-in-chamaleon-templates</id>
    <content type="html"><![CDATA[<p>If you want to prevent <a href="http://chameleon.repoze.org/" title="Chameleon is an excellent HTML templating engine">Chameleon</a> from rendering some portions of an HTML template you might be tempted to do something like this:</p>

<pre>
</br>
&lt;!-- &lt;div&gt;${context.name}&lt;/div&gt; --&gt;
</br>
</pre>


<p>However Chameleon will still evaluate what&rsquo;s inside the ${&hellip;} block even if it&rsquo;s within an HTML comment. Chameleon must do this because you might want to insert conditional comments.</p>

<p>This dummy tal:condition block will do the job:</p>

<pre>
</br>
&lt;span tal:condition="None"&gt;
  &lt;div&gt;${context.name}&lt;/div&gt;
&lt;/span&gt;
</br>
</pre>


<p>Chameleon ignore anything inside the condition block.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Moving to Spain]]></title>
    <link href="http://dannynavarro.net/2011/05/15/moving-to-spain/"/>
    <updated>2011-05-15T00:00:00+02:00</updated>
    <id>http://dannynavarro.net/2011/05/15/moving-to-spain</id>
    <content type="html"><![CDATA[<p>After almost 3 years in The Netherlands working as <a href="http://en.wikipedia.org/wiki/Proteomics">proteomics</a> informatician at¬†<a href="http://bioms.chem.uu.nl/">Albert Heck&rsquo;s lab</a>, I&rsquo;m moving to <a href="http://en.wikipedia.org/wiki/Sevilla">Seville</a>, Spain, to work as a web developer for<a href="http://yaco.es/"> Yaco Sistemas</a>, a fresh and dynamic open source friendly company.</p>

<p>This is an important shift in my career since I won&rsquo;t be working on proteomics informatics and academic research anymore.¬†I have mixed feelings about leaving proteomics. On one hand I like the area because there are plenty of tough challenges to be solved. But on the other hand I&rsquo;m glad I can dedicate all my time to develop web applications, that might not be as sophisticated as proteomics software, but that will be immediately useful for the <em>masses</em>. I love web development and the Python community but within proteomics I could only intersect with the Python web development community quite sporadically. Now I&rsquo;ll have the chance to be part of it full time.</p>

<p>Personally, The Netherlands is the most comfortable and easy-going country I ever lived. Here I had the chance to work with very smart people and made friends that will never forget. What I have learned during these years is priceless.</p>

<p>But I can&rsquo;t deny my origins, Spain is where I feel at home even if sometimes I don&rsquo;t find it too exciting because I&rsquo;m too familiar with the culture. However Seville is quite far from <a title="Pamplona" href="http://en.wikipedia.org/wiki/Pamplona">my hometown</a>, in the North of Spain. The culture in the South is very different from the North, so in a way, I&rsquo;ll be another foreigner excited about the peculiarities I discover about Andalusian culture.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Async Pyramid example done right]]></title>
    <link href="http://dannynavarro.net/2011/01/23/async-pyramid-example-done-right/"/>
    <updated>2011-01-23T00:00:00+01:00</updated>
    <id>http://dannynavarro.net/2011/01/23/async-pyramid-example-done-right</id>
    <content type="html"><![CDATA[<p>After speaking with <a href="http://mg.pov.lt/blog">Marius Gedminas</a> at freenode, he gave me enough hints to rewrite <a href="http://blog.dannynavarro.net/2011/01/14/async-web-apps-with-pyramid/">my previous async <i>view</i> example </a>with <i>locks</i> instead of <i>Value</i>, which is prone to race conditions. I also added a queue to allow jobs to wait for being processed.</p>

<br />


<br />


<pre>from multiprocessing import Process, Lock, Queue

job = 0
q = Queue(maxsize=3)
lock = Lock()

def work():
    import time; time.sleep(8)
    job = q.get()
    print("Job done: {0}".format(job))
    print("Queue size: {0}\n".format(q.qsize()))
    if not q.empty():
        work()
    else:
        lock.release()

def my_view(request):
    global job
    if not q.full():
        job += 1
        q.put(job)
        # Not running
        if lock.acquire(False):
            Process(target=work).start()
            print("Job {0} submitted and working on it".format(job))
        else:
            print("Job {0} submitted while working".format(job))
    else:
        print("Queue is full")
    print("Queue size: {0}\n".format(q.qsize()))
    return {'project':'asyncapp'}
<br />
</pre>


<p>With every request a job is sent. Here the queue accepts 3 jobs. The recursion in <i>work</i> makes sure there is only 1 process working at a time.</p>

<p>I will leave <a href="http://blog.dannynavarro.net/2011/01/14/async-web-apps-with-pyramid/">my previous example</a> with <i>Value</i> because it&rsquo;s easier to understand but this version is much safer.</p>

<p><strong>Update:</strong> You can avoid the use of locks by <a href="http://blog.doughellmann.com/2009/04/pymotw-multiprocessing-part-2.html"> using 2 queues</a>.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Async web apps with Pyramid?]]></title>
    <link href="http://dannynavarro.net/2011/01/14/async-web-apps-with-pyramid/"/>
    <updated>2011-01-14T00:00:00+01:00</updated>
    <id>http://dannynavarro.net/2011/01/14/async-web-apps-with-pyramid</id>
    <content type="html"><![CDATA[<p>For the last few months I&rsquo;ve been working in a kind of <a href="http://en.wikipedia.org/wiki/Content_management_system">CMS</a> for <a href="http://en.wikipedia.org/wiki/Proteomics">proteomics</a> results using <a href="http://docs.pylonsproject.org/projects/pyramid/dev/">pyramid</a> (in reality I started it with <a href="http://bfg.repoze.org/">repoze.bfg</a> which became pyramid after joining the pylons project).</p>

<p>My experience with pyramid has been really smooth until I had to write a form to parse huge input files in order to build <em>experiment sites</em>.</p>

<p>In an average view for an¬†<em>add form</em> I would return a response redirecting to the newly created <a title="models were renamed to resources after a long thread" href="http://www.mail-archive.com/pylons-devel@googlegroups.com/index.html#00910"><del>model</del> resource</a>. But in this case, the proteomics files can be quite large. I needed some way of having the view returning a response while the files were being parsed. Here is a simplified representation of how I made it work:</p>

<pre><span id="LC1">from multiprocessing import Value, Process</span>

<span id="LC3">is_parsing = Value('B', 0)</span>

<span id="LC5">def parse():</span>
<span id="LC6">    print "Parsing started"</span>
<span id="LC7">    import time; time.sleep(10)</span>
<span id="LC8">    print "Parsing is done"</span>
<span id="LC9">    is_parsing.value = False</span>

<span id="LC11">def my_view(request):</span>
<span id="LC13">¬†¬†¬†¬†if not is_parsing.value:</span>
<span id="LC14">¬†¬†¬†¬†¬†¬†¬†¬†is_parsing.value = True</span>
<span id="LC15">¬†¬†¬†¬†¬†¬†¬†¬†Process(target=parse).start()</span>
<span id="LC16">¬†¬†¬†¬†else:</span>
<span id="LC17">¬†¬†¬†¬†¬†¬†¬†¬†print("Still parsing...")</span>
<span id="LC18">¬†¬†¬†¬†return {'project':'asyncapp',</span>
<span id="LC10">            'is_parsing': is_parsing.value}</span></pre>


<br />


<br />


<p>Here I&rsquo;m launching another process to do the parsing while the web app returns the response without the parsing being done. The <em>is_building </em>variable is shared in both processes (no need of <em>global</em> statement). In my case I only want to run one parsing process at a time, so I didn&rsquo;t have the need for locks or queues.</p>

<p>In the template of this view I can either offer a form to create <em>an experiment </em>or inform that there is already a experiment site being built. When building I can have the browser <a href="http://plugins.jquery.com/project/refresh">polling</a> to check if the parsing is done.</p>

<p>That&rsquo;s enough in my case, I don&rsquo;t need to scale to thousands of users parsing multiple files at the same time, but I was curious about how to deal with that problem if I had to. I played a bit with different ideas I was given in the always supportive #repoze channel at <a href="http://freenode.net/">freenode</a>.</p>

<p>First, instead of multiple processes I tried <strong>OS threads, </strong>I know about the <a href="http://blip.tv/file/2232410">infamous GIL</a> but want to see it with my own eyes. However I got some intimidating random errors from paster/pyramid that were enough to drive me off that path.</p>

<p>I also¬†<a href="http://eventlet.net/doc/patching.html#monkeypatching-the-standard-library">monkeypatched</a> the standard library¬†with <a href="http://eventlet.net/">eventlet</a> so that the OS threads would become <strong>green threads</strong>. The dummy example I show above seemed to run fine but when trying in my real application I ran into more cryptic thread errors from monkeypatched¬†<a href="http://www.zodb.org/">ZODB</a>, which is what I use in my real app. I also tried <a href="http://www.gevent.org/">gevent</a> with similar results. <del datetime="2011-01-23T10:04:41+00:00">If you want to use eventlet or gevent you have to find another storage mechanism that works with green threads.</del> <strong>Update:</strong> I was monkeypatching incorrectly, <a href="http://braintrace.ru">Andrey Popp</a>&rsquo;s <a href="http://blog.dannynavarro.net/2011/01/14/async-web-apps-with-pyramid/#comment-58">comment</a> explains how to do it.</p>

<p>Another potential source of problems when scaling with<strong> long polling</strong>, specially if you would like to add a nice¬†responsive¬†progress bar and a kind of log showing what is being done while parsing.</p>

<p><a href="http://en.wikipedia.org/wiki/WebSockets">WebSockets</a> are being regarded as the ultimate solution to deal with this kind of problems. First of all, let&rsquo;s pretend websockets would be supported by all major browsers soon.</p>

<p>How can websockets be handled in pyramid? It turns out that dealing with websockets within <a href="http://www.python.org/dev/peps/pep-3333/">the WSGI protocol</a> is <a href="http://groups.google.com/group/paste-users/browse_thread/thread/2f3a5ba33b857c6c/2d63769fd9db6da3">messy</a>. However eventlet and gevent¬†<a href="http://eventlet.net/doc/modules/websocket.html">have</a> <a href="http://www.gelens.org/code/gevent-websocket/">ways</a> to have websockets working within WSGI. Theoretically you could run a monkeypatched pyramid application behind <a href="http://gunicorn.org/">gunicorn</a> which can make the websockets <a href="https://github.com/benoitc/gunicorn/tree/master/examples/websocket">accessible</a> in the <em>request.environ</em> in pyramid. There is still some websocket protocol tasks (i.e. handshaking, closing socket, etc.) which would make writing something looking like a normal pyramid view hard.</p>

<p>But it happens that¬†<a href="https://github.com/boothead">Ben Ford</a> has a already written a wrapper to take care of that problem: ¬†<a href="https://github.com/boothead/stargate">stargate</a> (as he says,¬†<em>communication for pyramids</em>). With stargate, in your pyramid app you create <em>websocket view</em> by subclassing from a base class that deals with the¬†minutiae¬†of the websocket protocol (up to v76, the latest version at the time of writing). In a websocket view, instead of returning anything from that view, you just write a handler to catch what is coming from the websocket. The great advantage of stargate is that you don&rsquo;t need to run another process to deal with websockets, you can handle websockets from within pyramid. Additionally, stargate has 100% unit test coverage and some <a href="http://boothead.github.com/stargate/">documentation</a>.</p>

<p>While websockets look like the way forward I think it&rsquo;s going to take some time for websockets to become mainstream in all browser, specially after mozilla announced it won&rsquo;t support websockets in the next release of firefox because of¬†<a href="http://hacks.mozilla.org/2010/12/websockets-disabled-in-firefox-4/">security issues</a>.</p>

<p>However, with¬†<a href="http://nodejs.org/">node.js</a>, it seems finally event driven web frameworks are becoming mainstream, bringing projects like¬†<a href="http://socket.io/">Socket.IO</a>. Socket.IO¬†provides an abstraction layer to the developer to write event driven web applications. Socket.IO gives the same way of writing regardless of what the browser supports, being websockets, long polling or Flash; the developer writes the app the same way.</p>

<p>Although initially Socket.IO is meant to be used with node.js, there is something available for the server side in Python:¬†<a href="https://github.com/SocketTornadIO/SocketTornad.IO">SocketTornad.IO</a>. It&rsquo;s built on top of¬†<a href="http://www.tornadoweb.org/">Tornado web framework</a>. In spite of Tornado having <a href="https://github.com/facebook/tornado/blob/master/tornado/wsgi.py#L194">some WSGI support</a>, I&rsquo;m afraid it¬†<a href="http://www.tornadoweb.org/documentation#wsgi-and-google-appengine">won&rsquo;t be easy</a> to have the async features when in WSGI mode.</p>

<p>If I were to support now many concurrent users in a highly responsive application I would probably ditch pyramid ¬†and go directly with SocketTornado.IO. Perhaps I will still be using pyramid for the non async part and have a front web server dispatching requests accordingly.</p>

<p>But it turns out that this is just a fun thought experiment, the multiprocess solution is fine for me because, like most web developers or bioinformaticians, for now I don&rsquo;t need to write highly responsive applications for thousands of users.</p>

<p><strong>Update: </strong><a href="http://mg.pov.lt/blog">Marius Gedminas</a> pointed out a better way to do this with locks. I will leave the code snippet using Value because is quite illustrative but you shouldn&rsquo;t use Value if you to do something similar, instead check a better example I wrote in <a href="http://blog.dannynavarro.net/2011/01/23/async-pyramid-example-done-right/">another post</a>.</p>

<p><strong>Update: </strong> Check <a href="https://github.com/abourget/pyramid_socketio">pyramid_socketio</a> for a newer version of async apps.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The bioinformatics curse]]></title>
    <link href="http://dannynavarro.net/2011/01/11/the-bioinformatics-curse/"/>
    <updated>2011-01-11T00:00:00+01:00</updated>
    <id>http://dannynavarro.net/2011/01/11/the-bioinformatics-curse</id>
    <content type="html"><![CDATA[<p>As a bioinformatician you will be considered a programmer by biologists and a biologist by programmers. When talking with programmers you will suck at programming, when talking with biologists you will suck at biology. Biologists don&rsquo;t want to know much about computing, understandably, they want to get their job done. Programmers might show some curiosity in biology but tend to shield themselves from biology complexity in order to get to get work done. As a bioinformatician you have to know enough of biology to be in the cutting-edge so what you research continues being relevant and keep improving your programming skills so you are still productive for what is expected of a programmer nowadays.</p>

<p>Some influential bioinformaticians group try to define the bioinformatics field as if it were precisely the research they are doing, frowning upon bioinformatics research not similar to theirs (or similar but superior to theirs). The followers of these groups try to imitate them so that they can be some day become <em>experts</em> in the field. I see also other bioinformaticians gathering together just because they work in biology using a computer, regardless of how little overlap there is in the things they do. It&rsquo;s like group therapy, sharing experiences with people marginalized for the same reason.</p>

<p>Bioinformatics field is still in the very beginning. The field is very broad and will eventually be fragmented in multiple <em>official</em> fields. Working in an emerging field can be very exciting because you don&rsquo;t have the constrains rules of an established field. But if social recognition is important to you, think twice when getting into bioinformatics. You&rsquo;d likely feel out-of-place wherever you go.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[ZSH prompt for virtualenv, git and bzr]]></title>
    <link href="http://dannynavarro.net/2010/10/16/zsh-prompt-for-virtualenv-git-and-bzr/"/>
    <updated>2010-10-16T00:00:00+02:00</updated>
    <id>http://dannynavarro.net/2010/10/16/zsh-prompt-for-virtualenv-git-and-bzr</id>
    <content type="html"><![CDATA[<p>Some of my colleagues are surprised I don&rsquo;t use NetBeans or Eclipse or some other fat IDE. In fact, I believe the most <a href="http://mg.pov.lt/blog/unix-is-an-ide.html">powerful IDE is UNIX</a>.</p>

<p>I also acknowledge that fine-tuning all your UNIX tools to your exact requirements can be cumbersome. But you don&rsquo;t need to customize everything from scratch. Open source is great because you can <em><a href="http://vimeo.com/4763707">steal</a></em> what other people are sharing and put it altogether as you like.</p>

<p>Lately I have been reading <a href="http://briancarper.net/blog/570/git-info-in-your-zsh-prompt">some</a> <a href="http://tech.blog.aknin.name/2010/10/14/zsh-and-virtualenv/">great</a> <a href="http://stevelosh.com/blog/2010/02/my-extravagant-zsh-prompt/">posts</a> about customization <a href="http://en.wikipedia.org/wiki/Zsh">ZSH</a>. I consider the shell prompt a fundamental part of the UNIX IDE. In the screenshot below I show how my customized ZSH prompt plays nicely with <a href="http://bazaar.canonical.com/">bzr</a>, <a href="http://git-scm.com/">git</a> and <a href="http://www.doughellmann.com/projects/virtualenvwrapper/">virtualenvwrapper</a>.</p>

<p><img class="alignnone size-full wp-image-109" title="zsh_demo" src="http://jdnavarro.files.wordpress.com/2010/10/zsh_demo1.png" alt="" width="536" height="754" /></p>

<p>I barely have done anything from scratch. I just stitched configurations and tips from these sources:</p>

<ol>
    <li>Prompt decorations: <a href="http://aperiodic.net/phil/prompt/">http://aperiodic.net/phil/prompt/</a>, <a href="http://git.sysphere.org/dotfiles/tree/zshrc">http://git.sysphere.org/dotfiles/tree/zshrc</a></li>
    <li>Zenburn theme: <a href="http://git.sysphere.org/dotfiles/tree/Xdefaults">http://git.sysphere.org/dotfiles/tree/Xdefaults</a></li>
    <li>git prompt hack: <a href="http://briancarper.net/blog/570/git-info-in-your-zsh-prompt">http://briancarper.net/blog/570/git-info-in-your-zsh-prompt</a></li>
    <li>virtualenv prompt hack: <a href="http://www.doughellmann.com/docs/virtualenvwrapper/tips.html#zsh-prompt">http://www.doughellmann.com/docs/virtualenvwrapper/tips.html#zsh-prompt</a></li>
    <li>bzr prompt hack: from scratch imitating git hack.</li>
</ol>


<p>End results:</p>

<ol>
    <li><a href="http://github.com/jdnavarro/dotfiles/blob/master/.zshrc#L164">.zshrc</a></li>
    <li>virtualenwrapper <a href="http://github.com/jdnavarro/dotfiles/blob/master/sandbox/virtualenvs/postactivate">postactivate</a> and <a href="http://github.com/jdnavarro/dotfiles/blob/master/sandbox/virtualenvs/postdeactivate">postdeactivate</a></li>
</ol>


<p>Isn&rsquo;t open source great? I would be flattered if you also can steal my configuration files ;)</p>

<p>In another blog post I&rsquo;ll write about my customizations for Vim, <a href="http://software.schmorp.de/pkg/rxvt-unicode.html">urxvt</a> and <a href="http://awesome.naquadah.org/">awesomewm</a> to reach the ultimate UNIX IDE.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The value of 'wasting' your time]]></title>
    <link href="http://dannynavarro.net/2010/08/06/the-value-of-wasting-your-time/"/>
    <updated>2010-08-06T00:00:00+02:00</updated>
    <id>http://dannynavarro.net/2010/08/06/the-value-of-wasting-your-time</id>
    <content type="html"><![CDATA[<p>I&rsquo;m the kind of guy who likes to learn just about everything just for fun. I have the feeling I don&rsquo;t really grasp something until I have real experience with it. That&rsquo;s why redoing something other people have done is the best activity I can think for learning what&rsquo;s the matter really about. But it seems some people have difficulties tolerating my views about learning. I sometimes hear things like:</p>

<p><em>Why do you reinvent the wheel? Why do you want to waste your time?</em></p>

<p>Well, if I hadn&rsquo;t &lsquo;wasted&rsquo; so much time during all these years I would still be doing terrible things like <a href="http://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454#1732454">using regex to parse HTML</a> with a crippled Perl scripts. The skills for what I&rsquo;m getting my salary are mostly from wasted time. I wouldn&rsquo;t be nowhere with only my <em>formal</em> training.</p>

<p>Information technology nowadays is mostly about about <strong>knowledge</strong> investment. Doing stuff is not as hard as learning how to do stuff orders of magnitude more efficiently. Learning is kind of accumulative, the more you learn the better you are at learning and the faster your efficiency grows. With computers is really hard to hit a physical limit where it&rsquo;s not possible to improve significantly more by learning.</p>

<p>It&rsquo;s <a href="http://en.wikipedia.org/wiki/The_Mythical_Man-Month">well known</a> that few highly productive people can beat large corporations made of people who work linearly with the skills they once learned in order to get a job.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Sharing proteomics data, trickier than it seems]]></title>
    <link href="http://dannynavarro.net/2010/07/31/sharing-proteomics-data-trickier-than-it-seems/"/>
    <updated>2010-07-31T00:00:00+02:00</updated>
    <id>http://dannynavarro.net/2010/07/31/sharing-proteomics-data-trickier-than-it-seems</id>
    <content type="html"><![CDATA[<p>Reading the <a href="http://cameronneylon.net/blog/metrics-of-use-how-to-align-researcher-incentives-with-outcomes/">blog post</a> from¬†<a href="http://cameronneylon.net">Cameron Neylon</a> about how research incentives should align with research outcomes made me see a clear relation with the problem of sharing data in proteomics.</p>

<p>Accessing genomics or transcriptomics data is more or less straightforward compared to proteomics data. You go to a data repository and download whatever you are looking for. Anyone who tries to do something similar in proteomics usually ends up downloading spreadsheets with incomplete data from supplemental material of published articles.</p>

<p>It&rsquo;s frequent to hear proteomics informaticians complaining about experimentalists not making their data easily available and how they could be so greedy of not publishing the data for what they have been funded with public money. But jumping into conclusions about experimentalists being greedy or sloppy is not fair to me. The real issue is far deeper than that.</p>

<p>First of all, in order to share proteomics data the first requirement is to have the proper infrastructure. Lately there has been some projects aiming to provide the sharing infrastructure.¬†I would say that the most popular proteomics repositories are <a href="http://www.peptideatlas.org/">PeptideAtlas</a>, <a href="http://www.humanproteinpedia.org/">Proteinpedia</a>, <a href="http://www.ebi.ac.uk/pride/">PRIDE</a> and <a href="https://proteomecommons.org/">ProteomeCommons</a>.</p>

<p>As far as I know, the main way Proteinpedia and PeptideAtlas handle data upload is with manual curators who study the format and the way the proteomics experiments were done. Then they come up with the best way to put the data in the repository. Usually is a combination of custom parsing with some manual editing to make experiments consistent in the repository. Obviously this kind of method is not that scalable for every proteomics experiment out there. In order to cope Proteinpedia focuses on human submissions only, whereas PeptideAtlas team is already looking into other¬†<a href="http://www.peptideatlas.org/upload/">solutions</a> to facilitate data submission.</p>

<p>PRIDE, in the other hand, accept only data submission in PRIDE XML format. The generation of this XML format is not supported by most of the proteomics tools experimentalists use. However the PRIDE team provide an <a href="http://code.google.com/p/pride-converter/">application</a> that tries to convert every format out there and every experiment design to the PRIDE XML format. But because they try cover every single aspect of every experiment, I&rsquo;ve seen experimentalists struggle when trying to fill all the forms. Moreover, they also don&rsquo;t like the rigidity of the model to depict what the proteomics experiment was about. It&rsquo;s true that there are some optional controlled vocabulary terms to give flexibility but still experiments have difficulties wrapping their head about how to use those terms.</p>

<p>This problem is not exclusive of PRIDE. Each proteomics lab uses its own mass spec terminology and frequently forms designed by developers with no first-hand experience making experiments don&rsquo;t match the terms the experimentalists would understand.¬†After all, experimentalists like to spend their time with experiments, they don&rsquo;t like spending their time in things that are considered bureaucracy.¬†The PRIDE team is aware of this problem a keeps trying with more¬†<a href="http://www.ebi.ac.uk/pride/proteomeharvest/">familiar ways</a> for experimentalists to fill form data.</p>

<p>ProteomeCommons seems to be the repository getting most traction. It&rsquo;s currently where most proteomics experimentalists are submitting their data to fend off journal editors&#8217; complains about the lack of published data. ProteomeCommons is built on top of the¬†<a href="https://trancheproject.org/">Tranche</a> network, a kind of global distributed filesystem, that potentially offers infinite scalability to store data by just adding more nodes to the network. The tranche network looks just like a big hard disk with several files. Everybody can upload anything they like. That&rsquo;s where ProteomeCommons comes in place, it&rsquo;s the web gateway to upload the data, the web application offers some options to annotate the data, but it&rsquo;s not as complete as what you have in the other databases. That&rsquo;s understandable because if they bothered the experimentalists with thousands of forms with mandatory fields, the experimentalist wouldn&rsquo;t submit their data to ProteomeCommons.¬†It&rsquo;s also worth mentioning that ProteomeCommons is not required to use Tranche network, any other proteomics repository could use Tranche network as a backend to store huge proteomics files. The rest of the repositories are currently looking into using the Tranche network to store the huge amounts of proteomics data, specially derived from raw data.</p>

<p>You might have notice the conspicuous¬†absence¬†of format standards in my description about the different repositories. If everybody used the same proteomics standards the infrastructural problems to share data would have been solved. Right?</p>

<p>The major effort to standardized proteomics formats is being carried out by <a href="http://www.psidev.info/">HUPO-PSI</a>. It&rsquo;s a kind of consortium where they have regular meetings where representatives of different proteomics groups among the world agree on what has to go in the standard and how. You can follow the discussions and chip in for what would you like to have in the formats.</p>

<p>Aside of the typical problems of something¬†<a href="http://www.codinghorror.com/blog/2005/06/the-pontiac-aztek-and-the-perils-of-design-by-committee.html">designed by committee</a>, it remains to be seen if mass spec vendors and proteomics software developers will fully embrace the standards. Proteomics data is highly¬†heterogeneous¬†by nature, there are very different kinds of proteomics experiments depending on what is the research being done. High quality proteomics experiments is not something that can be converted into an assembly line process where everything can be easily is fixed and standardized.</p>

<p>However the new stable¬†<a href="http://www.psidev.info/index.php?q=node/257">format</a> <a href="http://www.psidev.info/index.php?q=node/403">releases</a> from HUPO PSI look good enough to me to at least start making the data exchange among repositories possible. There is also the promise from several mass spec vendors of future commitment to fully support the standards. I hope all those promises don&rsquo;t end up in just that.</p>

<p>In my opinion all these infrastructural difficulties are going to be solved somehow relatively soon. The problem is that I don&rsquo;t think that just by solving the infrastructural problems everybody will start sharing data transparently. There are other difficulties.</p>

<p>The main reason experimentalists are, at least, uploading their data to Tranche is to avoid being bugged by proteomics journals into making their proteomics data available. Many proteomics journals are getting really <a href="http://www.mcponline.org/site/misc/ParisReport_Final.xhtml">serious</a> about this making the data available. Why proteomics journals are so interested in having the authors making their data available?</p>

<p>One could argue that editors of these journals believe in the moral imperative of making the data available but I don&rsquo;t buy ethics as the main reason. The majority of biomedical scientific journals are still for profit companies, not academic institutions. In order to survive they have to make money selling something as every other company. For a journal publishing articles with lots of citations from other journals, with lots citations themselves, are the best way to guarantee that companies and institutions will keep renewing the yearly subscriptions.</p>

<p>It&rsquo;s not something that I can&rsquo;t demonstrate with facts, but lately I&rsquo;m getting the feeling that proteomics is being disregarded by people in other biological fields as <em>low quality research</em>. After all proteomics is just a technology, a tool, to find out biological insights. Mass spec research by itself wouldn&rsquo;t get so much funding if it couldn&rsquo;t be used for biological research. What I think it&rsquo;s happening is that biologists are taking less seriously biological findings in pure proteomics journals. Most published proteomics experiments are irreproducible and if you start digging into the published data you frequently find many false positives. That&rsquo;s why proteomics journals editors are enforcing the experimentalists to release their data and make it as transparent as possible. They hope they can gain more credibility and get more citations from non-proteomics journals.</p>

<p>But still one can see that most experimentalists are reluctant to make their best data fully available.¬†Many informaticians trying to analyze the data think that this attitude is because of cultural resistance to change. Many of these informaticians try to evangelize the experimentalists about why is so important to share data. Among evangelists the most notable group is the¬†<a href="http://www.fixingproteomics.org/">Fix Proteomics Campaign</a>,¬†which proposes some habits to make proteomics more credible.</p>

<p>But experimentalists are not dummies. I have seen them changing really quickly any habit if they find something better. The problem is that making their data¬†transparently¬†available is worse for them and here is where I think the campaigns miss the point. Let me explain something unique about mass spectrometry proteomics that seems easily forgotten by many people.</p>

<p>Mass spectrometers are really expensive instruments. Getting the adequate skills to operate them takes several years of training. To make things more costly these instruments become obsolete in a matter of few years because there new ones are constantly new ones coming up with better features. When a new instrument arrives to the lab a lot of time is spent optimizing it and learning how to troubleshoot it. If you don&rsquo;t keep getting those new mass spectrometers you are left behind by the¬†competitors because they can get advantage of more powerful instruments.</p>

<p>How in academics is possible to maintain a high funding inflow? In a company you have to sell a a service or a product but you can&rsquo;t do so in an academic group. Usually you rely on grant agencies to provide funding. Granting agencies grant money by scientific productivity of the group. Publications in <em>reputable</em> journals are the main tangible measurement used by granting agencies for scientific productivity.</p>

<p>But most journals, as I said before, have to operate like companies. Proteomics data by itself is not publishable, if there is no story with some biological insight or some novel way to improve results, what will you write in a proteomics paper with just high quality data? Generating high quality proteomics data is damn difficult, I would say even more difficult than to come with fancy analysis of data. Let me explain.</p>

<p>People coming from genomics and transcriptomics fields sometimes forget that the chemical nature of proteins is much more diverse than DNA or RNA. After all, DNA and RNA have more or less homogeneous chemical properties regardless of its sequence. Proteins, in the other hand, are chemically completely different from each other depending on the sequence &ndash; that&rsquo;s why they can carry out so many molecular functions. A proteins from the¬†nucleus¬†are completely different than the proteins from the cytoplasmic membrane.</p>

<p>The proteome is also much more dynamic than the genome. The same cell under different conditions show completely different proteome profile. You also have to take chemical modifications of proteins into account, which are only detectable by probing the proteins directly. Chemical modifications like phosphorylation act as functional switches for proteins, a protein with a modification has also different chemical properties than the same protein without modification. The¬†heterogeneity¬†of proteins makes protein purification, proper separation, and identification by mass spec an entire field by itself.</p>

<p>So an experimentalist, who has had years of training just to be able to identify proteins and chemical modifications, might,¬†understandably,¬†lack the skills for sophisticated analysis that will make the story sexier for proteomics journals. Software to analyze proteomics data as a <em><a href="http://en.wikipedia.org/wiki/Power_user">power user</a></em><em>, </em>without programming knowledge, is still in the early days. As a developer I can see how difficult it is to make analysis software that covers every kind of proteomics experiment with a <em>point and click</em> interface.</p>

<p>The most logical step for an experimentalist when having good data would be to look for people specialized in analysis to come up with a powerful story. Usually the best people analyzing are independent proteomics informaticians that would do the analysis only if they get the credit for it. After all they have to also have to get funded to keep doing research and they can always claim they are the ones writing the paper. But even if proteomics informaticians give proper credit to the data generators in their papers &ndash; which I wouldn&rsquo;t say it&rsquo;s always true &ndash;, very few granting agencies will keep the experimental lab funded just to generate data that other people will use to write publications.</p>

<p>To tackle this problem the the most powerful experimental proteomics labs are trying to aggressively¬†hire programmers who can do analysis <em>in-house</em> so that the credit remains within the group. The first problem these groups face is that there are almost no proteomics informaticians in the job market. They have to invest in people with programming skills who will eventually get the proteomics knowledge necessary to make useful programs for analysis or to be able to analyze the data themselves.</p>

<p>Also, because of the lack of programming knowledge of the experimentalists it can be tricky for them to envision which potential programmers will have the skills required to become a good analyzer, not to mention how to motivate the programmers with an excellent about why to join their field. There are also programmers, where I include myself, that precisely look actively for this highly experimental labs instead of pure informatics groups in order to get a closer understanding of experimental data by interacting directly with the experimentalists.</p>

<p>But this kind of setting where data generators and informaticians try to work together is¬†propitious to get into¬†<a href="http://en.wikipedia.org/wiki/Dilbert">Dilbert-kind</a> of situations. I would say that it&rsquo;s mainly because of the misunderstanding generated by the technological gap.</p>

<p>I feel fortunate of working in <a href="http://bioms.chem.uu.nl/">my current group</a> because I think it&rsquo;s one of the few experimental proteomics lab where people are aware of this problem and actively try to improve the communication with the informaticians.</p>

<p>The final point I want to make in this post is that if the data generators were rewarded properly for what they are good at, generating unbeatable high quality, sharing proteomics data transparently, and as soon as it&rsquo;s generated, would become mainstream.¬†I see granting agencies rewards as the main cause for not sharing data because they usually don&rsquo;t reward the generation of data accordingly. They should also reward the labs that not only make the data available but make it as accessible as possible for data analyzers, so that proteomics research field would advance much faster than it&rsquo;s currently doing. I acknowledge granting agencies are changing slowly for the better but there is still a long way to go.</p>

<p>But understanding how granting agencies work and what are their motivations is still something quite fuzzy to me. I think I&rsquo;m still not old enough to understand the politics behind research funding.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[How to review supplemental material without revealing your identity]]></title>
    <link href="http://dannynavarro.net/2010/05/25/how-to-review-supplemental-material-without-revealing-your-identity/"/>
    <updated>2010-05-25T00:00:00+02:00</updated>
    <id>http://dannynavarro.net/2010/05/25/how-to-review-supplemental-material-without-revealing-your-identity</id>
    <content type="html"><![CDATA[<p>The <em>de facto</em> way to consider an article as scientifically valid is whether the publisher carried out a <a href="http://en.wikipedia.org/wiki/Peer_review">peer review</a> process or not. The reviewers are people with proven expertise in the field &ndash; by publishing peer reviewed articles in the area &ndash; who are capable of assessing the scientific value of an article. Because those reviewers can be direct competitors &ndash; who want to bog down the authors because they compete for funding or colleagues of the type: <em>you scratch my back, I scratch yours</em> &ndash; the editor doesn&rsquo;t unveil who are the reviewers. In my opinion the reviewers should be made public, both to the authors and to the readers of the article, but I would leave that for another post.</p>

<p>However keeping the reviewers anonymous these days is becoming more difficult because many scientific articles include supplemental material that can&rsquo;t be attached directly to the article, i. e. a huge list of proteins identified in a proteomics experiment. This poses a problem for editors and reviewers because by watching which <a href="http://computer.howstuffworks.com/internet/basics/question549.htm">IPs</a> are accessing the machine which is hosting the data the original authors can <a href="http://whatismyipaddress.com/">guess</a> who are the reviewers.</p>

<p>I have heard about this issue as a really huge problem for peer review process and from advocates of third party hosts with sophisticated technologies which anonymize reviewers. But it turns out that accessing any site in the web anonymously is not as obscure or complicated as it sounds.</p>

<p>A quick way &ndash; but maybe not so reliable &ndash; of anonymizing your web traffic is by googling for &lsquo;<a href="http://www.google.com/search?q=browse+anonymously">browse anonymously.</a>&rsquo; You can find many web <a href="http://en.wikipedia.org/wiki/HTTP_proxy">proxies</a> that claim to anonymize your identity. Usually you have to paste the web site you want to access anonymously and then you&rsquo;ll be redirected to the web page normally, albeit with a much slower load. The people who are hosting the server will see, at most, an IP address where the anonymous proxy is, that won&rsquo;t probably correspond to a place where any reviewers are located.</p>

<p>But I don&rsquo;t recommend using any proxy out there unless you really need to access something anonymously quickly and you have nothing in place. After all, who knows what they can do with your data, or if your IP leaks somewhere. I would recommend the use of the <a href="http://www.torproject.org/">Tor</a> network. Tor is an anonymity network where volunteers spread all over the world provide their machines to act as anonymizing proxies. Oversimplifying, Tor connects, encrypts and obfuscates the web traffic between you and the host with many of these proxies so that it becomes damn difficult to find out the original IP. When using a browser that goes through the Tor network the guys hosting the data will be seeing different random IPs all over the world with no relation whatsoever to each other.</p>

<p>There are different ways to setup Tor but if you want to use it without thinking too much go to the <a href="http://www.torproject.org/easy-download.html.en">download page</a> of Tor and get the Tor browser bundle. That will come with a firefox browser which is already configured for accessing the tor network. If in your institution or company, the network policy is controlled by a <a href="http://en.wikipedia.org/wiki/Bastard_Operator_From_Hell">fascist network administrator</a> who denies everything in the firewall regardless of the true danger for security is, go to <em>settings</em> and indicate you are behind a firewall.</p>

<p>By giving the link to the Tor bundle browser in the supplemental material the editor and the reviewers shouldn&rsquo;t have any problem accessing self-hosted data. Downloading the Tor bundle browser shouldn&rsquo;t be an obstacle, I haven&rsquo;t seen anyone complaining when asked to download a propietary viewer to visualize closed formats for raw data, which is quite common in proteomics.</p>

<p>However with this post I&rsquo;m not advocating to host your own data instead of sharing it. Hosting it yourself and sharing are not mutually exclusive. I think sharing your scientific data is a moral imperative when you are funded with public money. I encourage sending scientific data to as many public repositories as  possible, but I also think individual researchers have the right to host their own data if they want to.</p>

<p>I know it&rsquo;s hard to believe but many researchers who are funded with money coming from tax-payers are reluctanct to share their data, at least in the <a href="http://en.wikipedia.org/wiki/Proteomics">proteomics</a> community where I work. If their data is <em>stolen</em> and other people find more interesting things the original authors missed they lose the relevance necessary to keep getting funded, specially when the analyzers don&rsquo;t give enough credit to the generators of data which is quite frequent. But I will leave that for another post.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[The blogging itch]]></title>
    <link href="http://dannynavarro.net/2010/03/24/the-blogging-itch/"/>
    <updated>2010-03-24T00:00:00+01:00</updated>
    <id>http://dannynavarro.net/2010/03/24/the-blogging-itch</id>
    <content type="html"><![CDATA[<p>Starting a blog has been in my personal todo list for years. Finally, after encouraging myself with¬†<a href="http://www.codinghorror.com/blog/2006/03/users-dont-care-about-you.html">some</a> <a href="http://www.codinghorror.com/blog/2007/10/how-to-achieve-ultimate-blog-success-in-one-easy-step.html">old</a> <a title="post" href="http://www.codinghorror.com/blog/2006/02/fear-of-writing.html" target="_self">posts</a> from Jeff Atwood (yeah, I like reading <a title="Jeff Atwood" href="http://www.codinghorror.com/blog/" target="_self">Jeff Atwood</a> and I frequently agree with him), I decided to just kicked it off with whatever I have in my mind: why it has been so difficult to get started? Why now? It was not only procrastination, there has been something else. Let me explain.</p>

<p>I started using routinely a feed reader around 4 years ago. Since then I&rsquo;ve been constantly replacing the blog feeds I follow with others I found more interesting. Right now all the blogs I&rsquo;m following are excellently written, and I&rsquo;m not talking only about celebrity blogs, but also the kind of highly technical blogs that make it, for example, into <a href="http://planet.python.org/">Python planet</a>. When I think about the quality of writing I would like for my blog several blogs from Python planet come to my mind. But even if I put myself a much lower quality threshold to get started, it turns out that writing something of acceptable quality, just the writing, is indeed harder than it seems. I can <a href="http://zenhabits.net/2009/04/seven-productivity-tips-for-people-that-hate-gtd/" target="_self">allow myself to suck</a> but can&rsquo;t go public with something I know is total crap. Recently I reached a writing level where I&rsquo;m comfortable enough to go public.</p>

<p>But obviously publishing a decent blog is not only about writing properly. You need something to write about. For me it&rsquo;s not worth writing superficially just for the sake of writing. In order to comment on something I need to have a deep understanding of the matter, otherwise I can&rsquo;t confidently give a public opinion. But for that to happen I need something I didn&rsquo;t get until recently: specialized knowledge.</p>

<p>When I started my Biochemistry degree back in Spain I liked computers as a hobby¬† (I was a relatively early Linux user) but my real passion was molecular biology, the wet lab. Soon I realized how much tedious manual work and luck influenced in successful biological experiments. In the other hand, <em>experiments</em> using the computer were quick and you could somehow understand much better what was going on.</p>

<p>Later I worked for <a href="http://pandeylab.igm.jhmi.edu/akhilesh.html">Akhilesh Pandey</a> developing <a href="http://hprd.org/">HPRD</a>, a human protein database that included (and still does) plenty of high quality manually curated from scientific literature not found in any other biological databases. My role was a kind of bridge between the programmers, the curators and the biological requirements for the project. My research career started totally different to what it&rsquo;s expected from a young researcher, instead of specializing in something first and from there try to understand later how what you study contributes to science in general, I had to first understand the global picture before trying to get into the nitty-gritty. That didn&rsquo;t mean I didn&rsquo;t want to get deep into different areas. The problem was that I wanted to get into too many things at the same time. After some time the fields where I really ended up focusing have become fewer. Now, instead of working in large teams, I work more isolated in a very specialized projects within the area of proteomics informatics.</p>

<p>Then if finally I ended up working in a very specialized topic was the global view experience a waste of time? Absolutely not. My way of thinking has been critically shaped since then. I&rsquo;m the kind of person who has to have a clear reason of everything I do. Now it&rsquo;s clear for me on what I want to focus on, without losing the context of everything I do. I know what I want to learn and for what. I still maintain more or less the same goals that I had when I got into research, the difference now is how I want to reach those goals. But I&rsquo;ll leave my goals for another post.</p>

<p>In the end the lack of specialized knowledge has been a important blocker to start a blog. I didn&rsquo;t feel with enough authority to write acceptable posts for concrete topics. Now in <a href="http://en.wikipedia.org/wiki/Python_(programming_language)">Python</a> and <a href="http://en.wikipedia.org/wiki/Proteomics">proteomics</a> I&rsquo;m more or less getting above the knowledge threshold where I can start writing something critically.</p>

<p>At the same type proteomics informatics is a blend of very different specialized topics. In proteomics I still don&rsquo;t totally understand how a <a href="http://www.chemguide.co.uk/analysis/masspec/howitworks.html">mass spectrometer</a> works but of so much parsing, merging, querying, filtering, and plotting mass spec data I got a good handle of what mass spec proteomics data is like. About programming I&rsquo;m far from writing something I would qualify as <em>good code</em>. Even if my coding capabilities have improved over the years I qualify my code worse than I used to. In reality my code is better now, it&rsquo;s just that, with time, I&rsquo;m becoming more critical about what I would call good code. However I&rsquo;m fully aware that being so critical with my own code is a <a href="http://www.codinghorror.com/blog/2009/07/nobody-hates-software-more-than-software-developers.html">symptom of programming competence</a>. I feel I&rsquo;m on the right track, if I keep pushing like I&rsquo;m doing I&rsquo;ll eventually get to write something I could qualify as good enough. For now I feel competent enough in Python to start saying something meaningful about programming publicly.</p>

<p>The bottom line is that now I have some specific knowledge and a decent ability for writing. One would think that these factors provide the ideal scenario to start a blog. I know that having a blog is very important for my profession but that hasn&rsquo;t be the last push to start now. I&rsquo;m writing this post right now because I need it. Let me rephrase it: I&rsquo;m not forcing myself to write a blot, I need to write.</p>

<p>What is really happening is that blogging is just part of a bigger transformation I&rsquo;m going through. I&rsquo;ve been lurking for quite some time different open source communities, initially just to learn more from people who are way better than me in programming. But lately I have been developing a great admiration for certain communities and  individuals. I need to give them something back. I&rsquo;m gradually participating more in the community. Now I need show who I am, how I see the world, what I want in life and what do I admire and why.</p>

<p>That&rsquo;s why I&rsquo;m blogging.</p>
]]></content>
  </entry>
  
</feed>
